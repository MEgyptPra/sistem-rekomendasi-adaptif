{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7937ca-2b66-4067-940c-3505660f2317",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sqlalchemy psycopg2-binary nest_asyncio asyncpg tenacity scikit-learn matplotlib seaborn pandas numpy scipy tabulate tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295d206-a8e4-4368-9944-5604c3bbe854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Buat folder backup\n",
    "backup_dir = f\"backup_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "os.makedirs(backup_dir, exist_ok=True)\n",
    "\n",
    "# Backup semua hasil lama\n",
    "files_to_backup = [\n",
    "    'evaluation_df_cache.pkl',\n",
    "    'performance_results_cache.pkl',\n",
    "    'evaluation_results/results_summary_metrics.csv',\n",
    "    'evaluation_results/results_distribution_metrics.csv',\n",
    "    'evaluation_results/results_statistical_tests.json'\n",
    "]\n",
    "\n",
    "print(\"üì¶ Membackup hasil lama...\")\n",
    "for file in files_to_backup:\n",
    "    if os.path.exists(file):\n",
    "        shutil.copy(file, backup_dir)\n",
    "        print(f\"  ‚úÖ {file} ‚Üí {backup_dir}/\")\n",
    "\n",
    "# Hapus cache untuk re-run\n",
    "cache_files = [\n",
    "    'evaluation_df_cache.pkl',\n",
    "    'performance_results_cache.pkl'\n",
    "]\n",
    "\n",
    "print(\"\\nüóëÔ∏è Menghapus cache...\")\n",
    "for cache_file in cache_files:\n",
    "    if os.path.exists(cache_file):\n",
    "        os.remove(cache_file)\n",
    "        print(f\"  ‚úÖ Deleted: {cache_file}\")\n",
    "\n",
    "print(\"\\n‚úÖ Siap untuk re-run! Jalankan Cell 10.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe98885-460a-487c-9297-a28abcfc670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 3: SETUP DAN IMPORT LIBRARIES =====\n",
    "import nest_asyncio, asyncio\n",
    "from asyncio import Semaphore\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "# Terapkan patch asyncio untuk mengizinkan event loop berjalan di dalam notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import contextlib\n",
    "import logging\n",
    "\n",
    "# Konfigurasi logging dasar\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- KONEKSI DATABASE ASYNCHRONOUS ---\n",
    "# Pastikan URL database Anda benar\n",
    "DATABASE_URL = \"postgresql+asyncpg://user:rekompari@localhost:5432/pariwisata\"\n",
    "\n",
    "engine = create_async_engine(\n",
    "    DATABASE_URL,\n",
    "    pool_size=10,  # Ukuran pool koneksi\n",
    "    max_overflow=5, # Jumlah koneksi tambahan yang diizinkan\n",
    "    pool_timeout=30, # Waktu tunggu untuk mendapatkan koneksi\n",
    "    pool_recycle=1800 # Daur ulang koneksi setiap 30 menit\n",
    ")\n",
    "\n",
    "AsyncSessionLocal = sessionmaker(\n",
    "    bind=engine,\n",
    "    expire_on_commit=False,\n",
    "    class_=AsyncSession\n",
    ")\n",
    "\n",
    "@contextlib.asynccontextmanager\n",
    "async def get_db():\n",
    "    \"\"\"Provider sesi database asynchronous yang aman.\"\"\"\n",
    "    async with AsyncSessionLocal() as session:\n",
    "        try:\n",
    "            yield session\n",
    "        except Exception:\n",
    "            await session.rollback()\n",
    "            raise\n",
    "        finally:\n",
    "            await session.close()\n",
    "\n",
    "# --- HELPER UNTUK KEAMANAN KONEKSI ---\n",
    "\n",
    "# Semaphore untuk membatasi jumlah operasi DB bersamaan (mencegah overload)\n",
    "db_semaphore = Semaphore(5)\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=1, max=10))\n",
    "async def safe_db_operation(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Menjalankan operasi database dengan semaphore dan retry logic.\n",
    "    Ini penting untuk stabilitas evaluasi.\n",
    "    \"\"\"\n",
    "    async with db_semaphore:\n",
    "        try:\n",
    "            return await func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Operasi database gagal setelah beberapa percobaan: {e}\")\n",
    "            raise\n",
    "\n",
    "print(\"‚úÖ Database engine dan helper functions siap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5ec82-feec-421d-aef2-d9a58c58c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 4: IMPORT MODULES =====\n",
    "import sys\n",
    "# Hati-hati dengan path ini, sesuaikan dengan struktur folder Anda\n",
    "# Ini mengizinkan notebook untuk mengimpor file .py dari folder backend Anda\n",
    "sys.path.append('../pariwisata-recommender/backend')\n",
    "\n",
    "# Import model-model dari file .py Anda\n",
    "# Meskipun kita akan mendefinisikan ulang beberapa logika, kita masih butuh ini untuk perbandingan\n",
    "from app.services.base_recommender import BaseRecommender\n",
    "from app.services.collaborative_recommender import CollaborativeRecommender\n",
    "from app.services.content_based_recommender import ContentBasedRecommender\n",
    "from app.services.hybrid_recommender import HybridRecommender\n",
    "from app.services.mab_optimizer import MABOptimizer\n",
    "\n",
    "# Import library standar untuk analisis data dan numerik\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Import library untuk logging dan progress bar\n",
    "import logging\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Import library untuk machine learning dan evaluasi\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats # <--- TAMBAHAN BARU (untuk t-test)\n",
    "\n",
    "# Import library untuk visualisasi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Konfigurasi Tampilan ---\n",
    "# Atur gaya visualisasi\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "# Atur opsi tampilan pandas\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Atur logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "print(\"‚úÖ Semua modul berhasil di-import.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443fe967-5bb2-4429-8d6f-fe041c61895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 6: LOAD DAN SPLIT DATA (VERSI TEMPORAL) =====\n",
    "from sqlalchemy import select\n",
    "from app.models.rating import Rating # Pastikan model Rating diimpor\n",
    "\n",
    "async def load_ratings_df():\n",
    "    \"\"\"Load semua rating data dari database dengan penanganan koneksi yang baik.\"\"\"\n",
    "    logger.info(\"üì¶ Memuat data ratings dari database...\")\n",
    "    try:\n",
    "        async with get_db() as db:\n",
    "            # Mengurutkan berdasarkan created_at sangat penting untuk temporal split\n",
    "            query = select(Rating).order_by(Rating.created_at)\n",
    "            res = await db.execute(query)\n",
    "            rows = res.scalars().all()\n",
    "        \n",
    "        # Pastikan kolom created_at ada di model Rating Anda\n",
    "        data = []\n",
    "        has_created_at = False\n",
    "        if rows and hasattr(rows[0], 'created_at'):\n",
    "            has_created_at = True\n",
    "        \n",
    "        if has_created_at:\n",
    "            data = [{'user_id': r.user_id, \n",
    "                     'destination_id': r.destination_id, \n",
    "                     'rating': float(r.rating),\n",
    "                     'created_at': r.created_at \n",
    "                    } for r in rows]\n",
    "            logger.info(\"Berhasil memuat data dengan timestamp 'created_at'.\")\n",
    "        else:\n",
    "            # Fallback jika 'created_at' tidak ada di model/DB\n",
    "            logger.warning(\"Kolom 'created_at' tidak ditemukan!\")\n",
    "            logger.warning(\"Menggunakan timestamp acak sebagai fallback. Ini TIDAK ideal untuk evaluasi temporal.\")\n",
    "            data = [{'user_id': r.user_id, \n",
    "                     'destination_id': r.destination_id, \n",
    "                     'rating': float(r.rating),\n",
    "                     # Membuat timestamp acak untuk simulasi\n",
    "                     'created_at': pd.Timestamp.now() - pd.to_timedelta(np.random.randint(1, 365), 'd')\n",
    "                    } for r in rows]\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Pastikan tipe data benar\n",
    "        df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "        df['user_id'] = df['user_id'].astype(int)\n",
    "        df['destination_id'] = df['destination_id'].astype(int)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saat memuat ratings: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# --- FUNGSI SPLIT DATA TEMPORAL (LEBIH ROBUST) ---\n",
    "def create_temporal_split(df, test_size=0.2, min_ratings=5):\n",
    "    \"\"\"\n",
    "    Split data secara temporal per user (Stratified Temporal Split).\n",
    "    Hanya user dengan 'min_ratings' yang akan dimasukkan ke set evaluasi.\n",
    "    \"\"\"\n",
    "    print(f\"\\n‚úÇÔ∏è Membuat stratified temporal train/test split...\")\n",
    "    \n",
    "    user_rating_counts = df.groupby('user_id').size()\n",
    "    # Filter users: Hanya yang punya cukup rating untuk di-split\n",
    "    valid_users = user_rating_counts[user_rating_counts >= min_ratings].index\n",
    "    df_filtered = df[df['user_id'].isin(valid_users)].copy()\n",
    "    \n",
    "    print(f\"   Total users: {df['user_id'].nunique():,}\")\n",
    "    print(f\"   Users dengan ‚â•{min_ratings} ratings (valid untuk evaluasi): {len(valid_users):,}\")\n",
    "    \n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    # Ground truth (hanya item yang disukai >= 4.0 di test set)\n",
    "    ground_truth_cache_global = {}\n",
    "\n",
    "    for user_id in tqdm(valid_users, desc=\"Memisahkan data per user\"):\n",
    "        user_ratings = df_filtered[df_filtered['user_id'] == user_id].sort_values('created_at', ascending=True)\n",
    "        \n",
    "        # Tentukan titik split\n",
    "        split_idx = int(len(user_ratings) * (1 - test_size))\n",
    "        # Pastikan minimal 1 rating di train set\n",
    "        split_idx = max(1, split_idx) \n",
    "        # Pastikan minimal 1 rating di test set\n",
    "        if split_idx >= len(user_ratings):\n",
    "            split_idx = len(user_ratings) - 1\n",
    "\n",
    "        train_chunk = user_ratings.iloc[:split_idx]\n",
    "        test_chunk = user_ratings.iloc[split_idx:]\n",
    "        \n",
    "        train_data.append(train_chunk)\n",
    "        test_data.append(test_chunk)\n",
    "            \n",
    "        # Simpan ground truth (item yang disukai)\n",
    "        ground_truth_cache_global[user_id] = test_chunk[test_chunk['rating'] >= 4.0]['destination_id'].tolist()\n",
    "\n",
    "    train_df = pd.concat(train_data, ignore_index=True)\n",
    "    test_df = pd.concat(test_data, ignore_index=True) # Ini adalah test set kita\n",
    "    \n",
    "    print(f\"\\n‚úÖ Split selesai:\")\n",
    "    print(f\"   Train: {len(train_df):,} ratings ({train_df['user_id'].nunique():,} users)\")\n",
    "    print(f\"   Test:  {len(test_df):,} ratings ({test_df['user_id'].nunique():,} users)\")\n",
    "    \n",
    "    # Filter ground truth: hanya user yang punya item >= 4.0 di test set\n",
    "    eligible_users_global = [uid for uid, items in ground_truth_cache_global.items() if len(items) > 0]\n",
    "    print(f\"   Eligible users (punya item 'disukai' di test set): {len(eligible_users_global):,}\")\n",
    "\n",
    "    return train_df, test_df, ground_truth_cache_global, eligible_users_global\n",
    "\n",
    "# --- EKSEKUSI LOAD DAN SPLIT ---\n",
    "try:\n",
    "    # 1. Load data\n",
    "    ratings_df = await safe_db_operation(load_ratings_df)\n",
    "    print(f\"Total ratings dimuat: {len(ratings_df)}\")\n",
    "    print(f\"Unique users: {ratings_df['user_id'].nunique()}\")\n",
    "    print(f\"Unique destinations: {ratings_df['destination_id'].nunique()}\")\n",
    "\n",
    "    # 2. Eksekusi split\n",
    "    # Kita hanya perlu train_df untuk melatih model, dan ground_truth/eligible_users untuk evaluasi\n",
    "    train_df, test_df, ground_truth_cache, eligible_users = create_temporal_split(\n",
    "        ratings_df, \n",
    "        test_size=0.2, \n",
    "        min_ratings=5 # Butuh minimal 5 rating agar split 80/20 masuk akal\n",
    "    )\n",
    "\n",
    "    print(\"\\nVariabel global 'train_df', 'test_df', 'ground_truth_cache', 'eligible_users' telah dibuat.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Gagal pada CELL 6: {e}\")\n",
    "    # Buat DataFrame kosong agar sel berikutnya tidak error\n",
    "    train_df, test_df = pd.DataFrame(), pd.DataFrame()\n",
    "    ground_truth_cache, eligible_users = {}, []\n",
    "    print(\"Gagal memuat atau memisahkan data. Membuat DataFrame kosong.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f9227c-ac2f-448f-8067-cdf218b782f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 8: EVALUATION METRICS =====\n",
    "\n",
    "def precision_at_k(recs_ids, ground_truth_ids, k=10):\n",
    "    \"\"\"\n",
    "    Menghitung Precision@k.\n",
    "    Seberapa banyak item yang direkomendasikan relevan?\n",
    "    \n",
    "    Perbaikan: Menangani kasus jika len(recs) < k.\n",
    "    \"\"\"\n",
    "    if not recs_ids or k == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Ambil top-k rekomendasi\n",
    "    recs_ids = recs_ids[:k]\n",
    "    \n",
    "    # Denominator adalah jumlah item yang *benar-benar* direkomendasikan, maks k\n",
    "    denominator = min(k, len(recs_ids))\n",
    "    if denominator == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    # Hitung item yang relevan\n",
    "    hits = len(set(recs_ids) & set(ground_truth_ids))\n",
    "    return hits / denominator\n",
    "\n",
    "def recall_at_k(recs_ids, ground_truth_ids, k=10):\n",
    "    \"\"\"\n",
    "    Menghitung Recall@k.\n",
    "    Seberapa banyak item relevan yang berhasil ditemukan?\n",
    "    \"\"\"\n",
    "    if not recs_ids or not ground_truth_ids:\n",
    "        return 0.0 # Tidak ada recall jika tidak ada ground truth\n",
    "    \n",
    "    # Ambil top-k rekomendasi\n",
    "    recs_ids = recs_ids[:k]\n",
    "    \n",
    "    # Hitung item yang relevan\n",
    "    hits = len(set(recs_ids) & set(ground_truth_ids))\n",
    "    return hits / len(ground_truth_ids)\n",
    "\n",
    "def ndcg_at_k(recs_ids, ground_truth_ids, k=10):\n",
    "    \"\"\"\n",
    "    Menghitung Normalized Discounted Cumulative Gain (NDCG)@k.\n",
    "    Mengukur kualitas *ranking* (item relevan di atas lebih baik).\n",
    "    \"\"\"\n",
    "    if not recs_ids or not ground_truth_ids:\n",
    "        return 0.0\n",
    "        \n",
    "    recs_ids = recs_ids[:k]\n",
    "    \n",
    "    # --- Hitung DCG (Discounted Cumulative Gain) ---\n",
    "    dcg = 0.0\n",
    "    for i, did in enumerate(recs_ids):\n",
    "        if did in ground_truth_ids:\n",
    "            # Item relevan, tambahkan gain (1) didiskon oleh posisi logaritmik\n",
    "            dcg += 1 / np.log2(i + 2) # i+2 karena index mulai dari 0\n",
    "            \n",
    "    # --- Hitung IDCG (Ideal Discounted Cumulative Gain) ---\n",
    "    # Ini adalah DCG sempurna jika semua item relevan ada di k teratas\n",
    "    ideal_hits = min(len(ground_truth_ids), k)\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(ideal_hits))\n",
    "    \n",
    "    if idcg == 0:\n",
    "        return 0.0 # Tidak ada item relevan sama sekali\n",
    "        \n",
    "    return dcg / idcg\n",
    "\n",
    "# --- METRIK DIVERSITY (DARI CELL 11.5 LAMA) ---\n",
    "def intra_list_diversity(recommendations, item_categories):\n",
    "    \"\"\"\n",
    "    Menghitung Intra-List Diversity (ILD) berdasarkan kategori item.\n",
    "    Mengukur seberapa beragam item dalam SATU list rekomendasi.\n",
    "    Dihitung sebagai: (jumlah pasangan item beda kategori) / (total pasangan item)\n",
    "    \"\"\"\n",
    "    if not recommendations or len(recommendations) <= 1:\n",
    "        return 0.0 # Tidak ada diversity jika hanya 0 atau 1 item\n",
    "        \n",
    "    categories = []\n",
    "    for item_id in recommendations:\n",
    "        # Ambil kategori, fallback ke 'unknown' jika tidak ditemukan\n",
    "        # Ini penting agar item tanpa kategori tetap dihitung sebagai unik\n",
    "        categories.append(item_categories.get(item_id, f\"unknown_{item_id}\"))\n",
    "    \n",
    "    n = len(categories)\n",
    "    if n <= 1:\n",
    "        return 0.0\n",
    "        \n",
    "    different_pairs = 0\n",
    "    total_pairs = n * (n - 1) / 2\n",
    "    \n",
    "    if total_pairs == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    # Hitung jumlah pasangan yang *berbeda*\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if categories[i] != categories[j]:\n",
    "                different_pairs += 1\n",
    "    \n",
    "    return different_pairs / total_pairs\n",
    "\n",
    "print(\"‚úÖ Metrik evaluasi (Precision@k, Recall@k, NDCG@k, Intra-List Diversity) siap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8685f8af-f4b9-4cf7-a126-205207804836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 9: IMPLEMENTASI DAN INISIALISASI MODEL =====\n",
    "\n",
    "# Kita butuh `text` untuk query SQL mentah\n",
    "from sqlalchemy import text \n",
    "from app.models.destinations import Destination\n",
    "from app.models.category import Category\n",
    "\n",
    "# --- 1. IMPLEMENTASI COLLABORATIVE FILTERING (CF) ---\n",
    "#    (Menggunakan logika NMF yang sama dari tesis Anda, tapi dilatih di train_df)\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class ProperCollaborativeRecommender:\n",
    "    \"\"\"Implementasi CF (NMF) yang bersih untuk evaluasi.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # --- ALGORITMA INTI DARI FILE ANDA ---\n",
    "        # Ini adalah baris terpenting yang kita salin dari file .py Anda\n",
    "        # untuk memastikan metodologi tesis Anda tetap sama.\n",
    "        self.nmf_model = NMF(n_components=50, random_state=42, max_iter=500)\n",
    "        # -----------------------------------------\n",
    "        self.user_item_matrix = None\n",
    "        self.user_factors = None\n",
    "        self.item_factors = None\n",
    "        self.user_encoder = {} # map user_id -> matrix_index\n",
    "        self.item_encoder = {} # map item_id -> matrix_index\n",
    "        self.user_decoder = {} # map matrix_index -> user_id\n",
    "        self.item_decoder = {} # map matrix_index -> item_id\n",
    "        self.is_trained = False\n",
    "    \n",
    "    async def train(self, ratings_df: pd.DataFrame):\n",
    "        \"\"\"Train model CF hanya menggunakan train_df.\"\"\"\n",
    "        logger.info(\"ü§ñ Training ProperCollaborativeRecommender...\")\n",
    "        \n",
    "        # 1. Buat encoder (pemetaan)\n",
    "        unique_users = ratings_df['user_id'].unique()\n",
    "        unique_items = ratings_df['destination_id'].unique()\n",
    "        \n",
    "        self.user_encoder = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "        self.user_decoder = {idx: user_id for user_id, idx in self.user_encoder.items()}\n",
    "        self.item_encoder = {item_id: idx for idx, item_id in enumerate(unique_items)}\n",
    "        self.item_decoder = {idx: item_id for item_id, idx in self.item_encoder.items()}\n",
    "        \n",
    "        # 2. Buat sparse matrix\n",
    "        rows = [self.user_encoder[uid] for uid in ratings_df['user_id']]\n",
    "        cols = [self.item_encoder[did] for did in ratings_df['destination_id']]\n",
    "        data = ratings_df['rating'].values\n",
    "        \n",
    "        self.user_item_matrix = csr_matrix(\n",
    "            (data, (rows, cols)), \n",
    "            shape=(len(unique_users), len(unique_items))\n",
    "        )\n",
    "        \n",
    "        # 3. Latih model NMF\n",
    "        logger.info(f\"Melatih NMF dengan matrix shape: {self.user_item_matrix.shape}...\")\n",
    "        self.user_factors = self.nmf_model.fit_transform(self.user_item_matrix)\n",
    "        self.item_factors = self.nmf_model.components_\n",
    "        \n",
    "        self.is_trained = True\n",
    "        logger.info(\"‚úÖ ProperCollaborativeRecommender (NMF) berhasil di-train.\")\n",
    "        \n",
    "    async def predict(self, user_id, num_recommendations=10):\n",
    "        \"\"\"Prediksi skor untuk pengguna.\"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise Exception(\"CF model belum di-train.\")\n",
    "        \n",
    "        # Handle Cold Start: User tidak ada di data training\n",
    "        if user_id not in self.user_encoder:\n",
    "            logger.warning(f\"CF Cold Start: User {user_id} tidak ada di train_df.\")\n",
    "            return [] # Kembalikan list kosong\n",
    "            \n",
    "        # 1. Dapatkan index internal pengguna\n",
    "        user_idx = self.user_encoder[user_id]\n",
    "        \n",
    "        # 2. Rekonstruksi skor rating untuk pengguna ini\n",
    "        #    Ini adalah perkalian P_user * Q_items\n",
    "        user_scores = self.user_factors[user_idx].dot(self.item_factors)\n",
    "        \n",
    "        # 3. Hapus item yang sudah di-rating oleh pengguna di train_df\n",
    "        #    Kita ambil baris pengguna dari matrix asli\n",
    "        rated_item_indices = self.user_item_matrix[user_idx].indices\n",
    "        user_scores[rated_item_indices] = -1 # Beri skor sangat rendah\n",
    "        \n",
    "        # 4. Ambil top-k item\n",
    "        #    'argpartition' lebih cepat dari 'argsort' penuh\n",
    "        k = num_recommendations\n",
    "        top_k_indices = np.argpartition(user_scores, -k)[-k:]\n",
    "        # Urutkan k item tersebut\n",
    "        top_k_sorted = top_k_indices[np.argsort(user_scores[top_k_indices])][::-1]\n",
    "\n",
    "        # 5. Ubah kembali ke destination_id\n",
    "        recommendations = []\n",
    "        for item_idx in top_k_sorted:\n",
    "            destination_id = self.item_decoder[item_idx]\n",
    "            score = user_scores[item_idx]\n",
    "            # Normalisasi skor (0-1) untuk hybrid\n",
    "            normalized_score = max(0, min(1, score / (np.max(user_scores) + 1e-9)))\n",
    "            recommendations.append({\n",
    "                'destination_id': destination_id, \n",
    "                'score': normalized_score\n",
    "            })\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "\n",
    "# --- 2. IMPLEMENTASI CONTENT-BASED (CB) ---\n",
    "\n",
    "async def get_destination_categories_from_db():\n",
    "    \"\"\"Mengambil kategori destinasi NYATA dari database.\"\"\"\n",
    "    logger.info(\"Memuat kategori destinasi dari DB...\")\n",
    "    try:\n",
    "        async with get_db() as db:\n",
    "            # --- QUERY DIPERBAIKI ---\n",
    "            # Gunakan DISTINCT ON untuk mengambil HANYA 1 kategori per destinasi\n",
    "            # (diurutkan berdasarkan c.id terkecil)\n",
    "            query = text(\"\"\"\n",
    "            SELECT DISTINCT ON (d.id) \n",
    "                d.id as destination_id, \n",
    "                c.name as category_name\n",
    "            FROM destinations d\n",
    "            LEFT JOIN destination_categories dc ON d.id = dc.destination_id\n",
    "            LEFT JOIN categories c ON c.id = dc.category_id\n",
    "            ORDER BY d.id, c.id ASC\n",
    "            \"\"\")\n",
    "            # -----------------------\n",
    "            \n",
    "            result = await db.execute(query)\n",
    "            rows = result.fetchall()\n",
    "            \n",
    "            destination_categories = {}\n",
    "            for row in rows:\n",
    "                dest_id, category = row[0], row[1]\n",
    "                # Fallback jika kategori ternyata NULL\n",
    "                destination_categories[dest_id] = category if category else \"Wisata Lainnya\"\n",
    "            \n",
    "            logger.info(f\"Berhasil memuat {len(destination_categories)} kategori destinasi.\")\n",
    "            return destination_categories\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Tidak dapat mengakses kategori dari database: {e}. Menggunakan simulasi.\")\n",
    "        return None\n",
    "\n",
    "class ProperContentBasedRecommender:\n",
    "    \"\"\"Implementasi CB yang bersih untuk evaluasi.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.destinations_data = {}\n",
    "        self.category_popularity = {}\n",
    "        self.all_categories_map = {}\n",
    "        self.categories_list = ['Wisata Alam', 'Wisata Sejarah', 'Wisata Kuliner', 'Wisata Buatan', 'Wisata Keluarga', 'Wisata Lainnya']\n",
    "        self.is_trained = False\n",
    "\n",
    "    async def train(self):\n",
    "        \"\"\"Train CB model menggunakan train_df dan kategori dari DB.\"\"\"\n",
    "        logger.info(\"Training ProperContentBasedRecommender...\")\n",
    "        db_categories = await safe_db_operation(get_destination_categories_from_db)\n",
    "        if db_categories:\n",
    "            self.all_categories_map = db_categories\n",
    "            self.categories_list = list(set(db_categories.values()))\n",
    "        \n",
    "        all_destinations = ratings_df['destination_id'].unique()\n",
    "        \n",
    "        for dest_id in all_destinations:\n",
    "            category = self.all_categories_map.get(dest_id, self.categories_list[dest_id % len(self.categories_list)])\n",
    "            popularity = len(train_df[train_df['destination_id'] == dest_id])\n",
    "            self.destinations_data[dest_id] = {'category': category, 'popularity': popularity}\n",
    "            if dest_id not in self.all_categories_map:\n",
    "                self.all_categories_map[dest_id] = category\n",
    "        \n",
    "        for category in self.categories_list:\n",
    "            cat_dest_ids = [did for did, data in self.destinations_data.items() if data['category'] == category]\n",
    "            if cat_dest_ids:\n",
    "                pop_series = train_df[train_df['destination_id'].isin(cat_dest_ids)]['destination_id'].value_counts()\n",
    "                self.category_popularity[category] = pop_series\n",
    "        \n",
    "        self.is_trained = True\n",
    "        logger.info(\"‚úÖ ProperContentBasedRecommender berhasil di-train.\")\n",
    "\n",
    "    async def predict(self, user_id, num_recommendations=10):\n",
    "        if not self.is_trained: raise Exception(\"CB model belum di-train.\")\n",
    "        user_ratings = train_df[train_df['user_id'] == user_id]\n",
    "        rated_items = set(user_ratings['destination_id'].tolist())\n",
    "        \n",
    "        if user_ratings.empty: # Cold Start\n",
    "            recommendations = []\n",
    "            num_per_cat = max(1, num_recommendations // len(self.category_popularity))\n",
    "            for category, pop_series in self.category_popularity.items():\n",
    "                if pop_series is not None and not pop_series.empty:\n",
    "                    recommendations.extend(pop_series.head(num_per_cat).index.tolist())\n",
    "            final_recs = [dest_id for dest_id in recommendations if dest_id not in rated_items]\n",
    "            final_recs = list(dict.fromkeys(final_recs))\n",
    "            return [{'destination_id': dest_id, 'score': 0.5} for dest_id in final_recs[:num_recommendations]]\n",
    "\n",
    "        user_categories = [self.destinations_data[did]['category'] for did in user_ratings['destination_id'] if did in self.destinations_data]\n",
    "        if not user_categories: return []\n",
    "        \n",
    "        category_counts = Counter(user_categories)\n",
    "        preferred_categories = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        recommendations = []\n",
    "        for category, _ in preferred_categories:\n",
    "            if category in self.category_popularity and self.category_popularity[category] is not None:\n",
    "                for dest_id in self.category_popularity[category].index:\n",
    "                    if dest_id not in rated_items and dest_id not in recommendations:\n",
    "                        recommendations.append(dest_id)\n",
    "        \n",
    "        return [{'destination_id': dest_id, 'score': 1.0 / (i + 1)} for i, dest_id in enumerate(recommendations[:num_recommendations])]\n",
    "\n",
    "    def get_categories(self):\n",
    "        return self.all_categories_map\n",
    "\n",
    "# --- 3. IMPLEMENTASI CONTEXT-AWARE ---\n",
    "\n",
    "class ContextAwareComponent:\n",
    "    \"\"\"\n",
    "    Mensimulasikan konteks yang kaya (cuaca, musim) berdasarkan tesis\n",
    "    dan file real_time_data.py.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Logika disalin dari file real_time_data.py Anda\n",
    "        self.weather_conditions = [\"cerah\", \"berawan\", \"hujan_ringan\", \"hujan_lebat\"]\n",
    "        self.seasons = [\"kemarau\", \"hujan\"]\n",
    "        self.kemarau_months = [5, 6, 7, 8, 9, 10]  # Mei - Oktober\n",
    "        self.hujan_months = [11, 12, 1, 2, 3, 4]    # November - April\n",
    "        logger.info(\"ContextAwareComponent (rich context) diinisialisasi.\")\n",
    "\n",
    "    def _get_season(self, month):\n",
    "        \"\"\"Helper untuk menentukan musim di Indonesia.\"\"\"\n",
    "        if month in self.kemarau_months:\n",
    "            return \"kemarau\"\n",
    "        else:\n",
    "            return \"hujan\"\n",
    "\n",
    "    def get_context(self, user_id):\n",
    "        \"\"\"\n",
    "        Mensimulasikan konteks yang kaya secara deterministik (konsisten per user).\n",
    "        Diadaptasi dari 'get_mock_context' di real_time_data.py.\n",
    "        \"\"\"\n",
    "        # Seed berdasarkan user_id agar konteksnya konsisten\n",
    "        random.seed(user_id)\n",
    "        \n",
    "        # --- Waktu (Logika Lama) ---\n",
    "        hour = random.randint(8, 22)\n",
    "        is_weekend = random.choice([True, False])\n",
    "        time_of_day = 'night'\n",
    "        if 8 <= hour < 11: time_of_day = 'morning'\n",
    "        elif 11 <= hour < 15: time_of_day = 'afternoon'\n",
    "        elif 15 <= hour < 18: time_of_day = 'evening'\n",
    "\n",
    "        # --- Musim & Cuaca (Logika BARU dari real_time_data.py) ---\n",
    "        random_month = random.randint(1, 12)\n",
    "        season = self._get_season(random_month)\n",
    "        \n",
    "        if season == \"hujan\":\n",
    "            # Bobot saat musim hujan\n",
    "            weather = random.choices(self.weather_conditions, weights=[0.2, 0.3, 0.3, 0.2])[0]\n",
    "        else: # kemarau\n",
    "            # Bobot saat musim kemarau\n",
    "            weather = random.choices(self.weather_conditions, weights=[0.6, 0.3, 0.08, 0.02])[0]\n",
    "        \n",
    "        # Mengembalikan konteks yang LENGKAP\n",
    "        return {\n",
    "            'time_of_day': time_of_day,\n",
    "            'is_weekend': is_weekend,\n",
    "            'hour': hour,\n",
    "            'weather': weather,  # <--- Konteks Baru\n",
    "            'season': season      # <--- Konteks Baru\n",
    "        }\n",
    "\n",
    "    def get_contextual_boost(self, recommendations, context, item_categories):\n",
    "        \"\"\"\n",
    "        Memberikan 'boost' skor berdasarkan KONTEKS YANG KAYA (cuaca, waktu).\n",
    "        \"\"\"\n",
    "        boosted_recs = []\n",
    "        for rec in recommendations:\n",
    "            dest_id = rec['destination_id']\n",
    "            # Dapatkan kategori item (misal: 'Wisata Alam', 'Wisata Kuliner')\n",
    "            category = item_categories.get(dest_id, \"Wisata Lainnya\")\n",
    "            boost = 0.0\n",
    "            \n",
    "            # --- Logika Boost yang Diperbarui (Contoh) ---\n",
    "            \n",
    "            # 1. Boost Waktu (lama)\n",
    "            if context['time_of_day'] == 'evening' and category == 'Wisata Kuliner':\n",
    "                boost += 0.15\n",
    "            \n",
    "            # 2. Boost Cuaca (BARU)\n",
    "            # Jika cuaca 'cerah', prioritaskan 'Wisata Alam'\n",
    "            if context['weather'] == 'cerah' and category == 'Wisata Alam':\n",
    "                boost += 0.1\n",
    "            \n",
    "            # Jika 'hujan', prioritaskan 'Wisata Buatan' (misal: museum, mall, indoor)\n",
    "            if context['weather'].startswith('hujan') and category == 'Wisata Buatan':\n",
    "                boost += 0.1\n",
    "            \n",
    "            # 3. Boost Musim/Akhir Pekan (BARU)\n",
    "            # Jika 'kemarau' DAN 'akhir pekan', prioritaskan 'Wisata Keluarga'\n",
    "            if context['season'] == 'kemarau' and context['is_weekend'] and category == 'Wisata Keluarga':\n",
    "                boost += 0.1\n",
    "            \n",
    "            # ---------------------------------\n",
    "            \n",
    "            new_rec = rec.copy()\n",
    "            new_rec['score'] += boost # Tambahkan boost ke skor asli\n",
    "            boosted_recs.append(new_rec)\n",
    "            \n",
    "        return boosted_recs\n",
    "\n",
    "# --- 4. IMPLEMENTASI MMR RERANKER ---\n",
    "\n",
    "class MMRReranker:\n",
    "    def __init__(self, item_categories_map):\n",
    "        self.item_categories = item_categories_map\n",
    "        self.category_cache = {}\n",
    "\n",
    "    def _get_category(self, item_id):\n",
    "        if item_id not in self.category_cache:\n",
    "            self.category_cache[item_id] = self.item_categories.get(item_id, f\"unknown_{item_id}\")\n",
    "        return self.category_cache[item_id]\n",
    "\n",
    "    def _get_similarity(self, item_id1, item_id2):\n",
    "        return 1.0 if self._get_category(item_id1) == self._get_category(item_id2) else 0.0\n",
    "\n",
    "    def rerank(self, recommendations, lambda_val=0.5, k=10):\n",
    "        if not recommendations: return []\n",
    "        original_recs = {rec['destination_id']: rec['score'] for rec in recommendations}\n",
    "        candidates = list(original_recs.keys())\n",
    "        reranked_list = []\n",
    "        \n",
    "        while len(reranked_list) < k and candidates:\n",
    "            best_item = None; best_mmr_score = -float('inf')\n",
    "            for item_id in candidates:\n",
    "                relevance = original_recs[item_id]\n",
    "                if not reranked_list:\n",
    "                    similarity = 0.0\n",
    "                else:\n",
    "                    similarity = max(self._get_similarity(item_id, selected_id) for selected_id in reranked_list)\n",
    "                mmr_score = (lambda_val * relevance) - ((1 - lambda_val) * similarity)\n",
    "                if mmr_score > best_mmr_score:\n",
    "                    best_mmr_score = mmr_score; best_item = item_id\n",
    "            if best_item:\n",
    "                reranked_list.append(best_item); candidates.remove(best_item)\n",
    "            else: break\n",
    "        return reranked_list\n",
    "\n",
    "# --- 5. IMPLEMENTASI MULTI-ARMED BANDIT (MAB) ---\n",
    "\n",
    "class SimpleMAB:\n",
    "    \"\"\"Implementasi UCB1 MAB untuk memilih lambda.\"\"\"\n",
    "    def __init__(self, n_arms=11):\n",
    "        # 11 arms untuk lambda [0.0, 0.1, ..., 1.0]\n",
    "        self.n_arms = n_arms\n",
    "        self.arms = np.linspace(0, 1, n_arms)\n",
    "        self.counts = np.zeros(n_arms, dtype=int)\n",
    "        # Ganti nama 'rewards' menjadi 'avg_rewards' agar lebih jelas\n",
    "        self.avg_rewards = np.zeros(n_arms, dtype=float)\n",
    "        self.total_pulls = 0\n",
    "\n",
    "    def select_arm(self):\n",
    "        \"\"\"Pilih arm (lambda) menggunakan UCB1 DAN update count.\"\"\"\n",
    "        \n",
    "        # --- LOGIKA KEMBALI KE SINI ---\n",
    "        self.total_pulls += 1\n",
    "        \n",
    "        # --- Fase Eksplorasi Awal ---\n",
    "        # Pastikan setiap arm dicoba setidaknya sekali\n",
    "        for arm in range(self.n_arms):\n",
    "            if self.counts[arm] == 0:\n",
    "                # --- LOGIKA KEMBALI KE SINI ---\n",
    "                self.counts[arm] += 1\n",
    "                return arm, self.arms[arm]\n",
    "        \n",
    "        # --- Fase Eksploitasi/Eksplorasi (UCB1) ---\n",
    "        # (avg_rewards sudah tersimpan)\n",
    "        \n",
    "        # Tambahkan 1e-9 untuk keamanan jika total_pulls = 0 (meskipun seharusnya tidak)\n",
    "        exploration_bonus = np.sqrt(2 * np.log(self.total_pulls + 1e-9) / self.counts)\n",
    "        ucb_values = self.avg_rewards + exploration_bonus\n",
    "        \n",
    "        selected_arm = np.argmax(ucb_values)\n",
    "        \n",
    "        # --- LOGIKA KEMBALI KE SINI ---\n",
    "        self.counts[selected_arm] += 1\n",
    "        return selected_arm, self.arms[selected_arm]\n",
    "\n",
    "    def update(self, arm_index, reward):\n",
    "        \"\"\"Update reward untuk arm yang dipilih.\"\"\"\n",
    "        \n",
    "        # --- LOGIKA DIPINDAHKAN DARI SINI ---\n",
    "        # self.total_pulls += 1 (sudah pindah ke select_arm)\n",
    "        # self.counts[arm_index] += 1 (sudah pindah ke select_arm)\n",
    "        # ------------------------------------\n",
    "        \n",
    "        n = self.counts[arm_index]\n",
    "        \n",
    "        # Jika n=0 (sebagai pengaman, seharusnya tidak terjadi)\n",
    "        if n == 0:\n",
    "            return\n",
    "\n",
    "        # Gunakan formula update incremental yang stabil secara numerik\n",
    "        # R_n = R_{n-1} + (x_n - R_{n-1}) / n\n",
    "        old_avg_reward = self.avg_rewards[arm_index]\n",
    "        new_avg_reward = old_avg_reward + (reward - old_avg_reward) / n\n",
    "        \n",
    "        self.avg_rewards[arm_index] = new_avg_reward\n",
    "\n",
    "# --- 6. IMPLEMENTASI HYBRID RECOMMENDER (ORKESTRATOR) ---\n",
    "\n",
    "class ProperHybridRecommender:\n",
    "    \"\"\"Orkestrator yang bersih untuk menjalankan semua 5 strategi.\"\"\"\n",
    "    def __init__(self, cf_model, cb_model, context_comp, mmr_reranker, mab):\n",
    "        self.cf = cf_model; self.cb = cb_model; self.context = context_comp\n",
    "        self.mmr = mmr_reranker; self.mab = mab\n",
    "        # Bobot hybrid (sesuai file .py produksi)\n",
    "        self.cf_weight = 0.5\n",
    "        self.cb_weight = 0.5\n",
    "\n",
    "    async def _combine_scores(self, cf_recs, cb_recs):\n",
    "        combined = {}\n",
    "        for rec in cf_recs: combined[rec['destination_id']] = combined.get(rec['destination_id'], 0) + rec['score'] * self.cf_weight\n",
    "        for rec in cb_recs: combined[rec['destination_id']] = combined.get(rec['destination_id'], 0) + rec['score'] * self.cb_weight\n",
    "        sorted_recs = sorted(combined.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [{'destination_id': did, 'score': score} for did, score in sorted_recs]\n",
    "\n",
    "    async def predict(self, user_id, strategy='hybrid_mab_mmr', k=10):\n",
    "        \"\"\"Satu fungsi untuk menjalankan salah satu dari 5 strategi.\"\"\"\n",
    "        \n",
    "        # --- 1. CF (Baseline 1) ---\n",
    "        if strategy == 'cf':\n",
    "            recs = await self.cf.predict(user_id, num_recommendations=k)\n",
    "            return [r['destination_id'] for r in recs]\n",
    "        \n",
    "        # --- 2. CB (Baseline 2) ---\n",
    "        if strategy == 'cb':\n",
    "            recs = await self.cb.predict(user_id, num_recommendations=k)\n",
    "            return [r['destination_id'] for r in recs]\n",
    "\n",
    "        # --- Untuk semua strategi Hybrid ---\n",
    "        cf_recs_raw = await self.cf.predict(user_id, num_recommendations=50)\n",
    "        cb_recs_raw = await self.cb.predict(user_id, num_recommendations=50)\n",
    "        combined_recs = await self._combine_scores(cf_recs_raw, cb_recs_raw)\n",
    "        user_context = self.context.get_context(user_id)\n",
    "        contextual_recs = self.context.get_contextual_boost(combined_recs, user_context, self.cb.get_categories())\n",
    "        sorted_contextual_recs = sorted(contextual_recs, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "        # --- 3. Hybrid (Baseline 3) ---\n",
    "        if strategy == 'hybrid':\n",
    "            return [r['destination_id'] for r in sorted_contextual_recs[:k]]\n",
    "\n",
    "        # --- 4. Hybrid + Static MMR (Baseline 4) ---\n",
    "        if strategy == 'hybrid_mmr_static':\n",
    "            return self.mmr.rerank(sorted_contextual_recs, lambda_val=0.5, k=k)\n",
    "\n",
    "        # --- 5. Hybrid + MAB + MMR (Proposed Model) ---\n",
    "        if strategy == 'hybrid_mab_mmr':\n",
    "            arm_index, dynamic_lambda = self.mab.select_arm()\n",
    "            reranked_ids = self.mmr.rerank(sorted_contextual_recs, lambda_val=dynamic_lambda, k=k)\n",
    "            # Kembalikan ID dan arm_index yang dipilih (penting untuk CELL 11)\n",
    "            return reranked_ids, arm_index \n",
    "        \n",
    "        raise ValueError(f\"Strategi tidak dikenal: {strategy}\")\n",
    "\n",
    "# --- 7. INISIALISASI SEMUA KOMPONEN ---\n",
    "\n",
    "async def initialize_all_models():\n",
    "    \"\"\"Menginisialisasi dan melatih semua komponen model.\"\"\"\n",
    "    global collab_model_engine, cb_model_engine, mab_engine, hybrid_model_engine, mmr_reranker\n",
    "    \n",
    "    try:\n",
    "        # 1. Latih CF\n",
    "        collab_model_engine = ProperCollaborativeRecommender()\n",
    "        await collab_model_engine.train(train_df) # Latih dengan train_df\n",
    "        \n",
    "        # 2. Latih CB\n",
    "        cb_model_engine = ProperContentBasedRecommender()\n",
    "        await cb_model_engine.train()\n",
    "        \n",
    "        # 3. Dapatkan map kategori dari CB (penting untuk MMR)\n",
    "        item_categories_map = cb_model_engine.get_categories()\n",
    "        if not item_categories_map:\n",
    "            raise Exception(\"Gagal mendapatkan map kategori dari CB model.\")\n",
    "        \n",
    "        # 4. Inisialisasi komponen lain\n",
    "        context_comp = ContextAwareComponent()\n",
    "        mmr_reranker = MMRReranker(item_categories_map)\n",
    "        mab_engine = SimpleMAB(n_arms=11)\n",
    "        \n",
    "        # 5. Inisialisasi Orkestrator Hybrid\n",
    "        hybrid_model_engine = ProperHybridRecommender(\n",
    "            cf_model=collab_model_engine,\n",
    "            cb_model=cb_model_engine,\n",
    "            context_comp=context_comp,\n",
    "            mmr_reranker=mmr_reranker,\n",
    "            mab=mab_engine\n",
    "        )\n",
    "        \n",
    "        logger.info(\"‚úÖ‚úÖ‚úÖ Semua komponen model berhasil diinisialisasi.\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Gagal menginisialisasi model: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- EKSEKUSI INISIALISASI ---\n",
    "# Variabel global akan dibuat:\n",
    "# - collab_model_engine (Model CF)\n",
    "# - cb_model_engine (Model CB)\n",
    "# - mab_engine (Model MAB)\n",
    "# - hybrid_model_engine (Orkestrator utama)\n",
    "\n",
    "if await initialize_all_models():\n",
    "    print(\"‚úÖ Engine model (hybrid_model_engine, dll.) siap digunakan.\")\n",
    "    \n",
    "    # Tes cepat\n",
    "    if eligible_users:\n",
    "        test_user = eligible_users[0]\n",
    "        print(f\"Menjalankan tes prediksi untuk user {test_user}...\")\n",
    "        recs = await hybrid_model_engine.predict(test_user, strategy='hybrid_mab_mmr', k=5)\n",
    "        print(f\"Hasil tes MAB-MMR (recs, arm): {recs}\")\n",
    "        recs_cf = await hybrid_model_engine.predict(test_user, strategy='cf', k=5)\n",
    "        print(f\"Hasil tes CF: {recs_cf}\")\n",
    "    else:\n",
    "        print(\"Tidak ada user yang eligible untuk tes cepat.\")\n",
    "else:\n",
    "    print(\"‚ùå Gagal menginisialisasi engine model. Cek error di atas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4f3e8-bd5c-4894-ae25-b37d8348f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 10: EKSEKUSI EVALUASI BATCH =====\n",
    "import pickle\n",
    "\n",
    "# Nama file untuk menyimpan cache hasil evaluasi\n",
    "EVAL_CACHE_FILE = 'evaluation_df_cache.pkl'\n",
    "\n",
    "async def run_evaluation_for_user(user_id, model_engine):\n",
    "    \"\"\"\n",
    "    Menjalankan SEMUA 5 model untuk SATU pengguna dan mengembalikan hasilnya.\n",
    "    Didesain untuk dijalankan secara konkuren.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- Baseline 1: CF ---\n",
    "        cf_recs = await model_engine.predict(user_id, strategy='cf', k=10)\n",
    "        \n",
    "        # --- Baseline 2: CB ---\n",
    "        cb_recs = await model_engine.predict(user_id, strategy='cb', k=10)\n",
    "        \n",
    "        # --- Baseline 3: Hybrid (CF+CB+Context) ---\n",
    "        hybrid_recs = await model_engine.predict(user_id, strategy='hybrid', k=10)\n",
    "        \n",
    "        # --- Baseline 4: Hybrid + Static MMR (lambda=0.5) ---\n",
    "        static_mmr_recs = await model_engine.predict(user_id, strategy='hybrid_mmr_static', k=10)\n",
    "        \n",
    "        # --- Baseline 5 (Proposed): Hybrid + MAB + MMR ---\n",
    "        # Ini mengembalikan (list_ids, arm_index)\n",
    "        mab_recs, arm_index = await model_engine.predict(user_id, strategy='hybrid_mab_mmr', k=10)\n",
    "        \n",
    "        # Kembalikan sebagai dict untuk DataFrame\n",
    "        return {\n",
    "            'user_id': user_id,\n",
    "            'recommendations_cf': cf_recs,\n",
    "            'recommendations_cb': cb_recs,\n",
    "            'recommendations_hybrid': hybrid_recs,\n",
    "            'recommendations_hybrid_mmr_static': static_mmr_recs,\n",
    "            'recommendations_hybrid_mab_mmr': mab_recs,\n",
    "            'mab_arm_index': arm_index # <--- Simpan arm yang dipilih MAB\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Gagal mengevaluasi pengguna {user_id}: {e}\")\n",
    "        # Kembalikan data kosong agar tidak merusak batch\n",
    "        return {\n",
    "            'user_id': user_id,\n",
    "            'recommendations_cf': [],\n",
    "            'recommendations_cb': [],\n",
    "            'recommendations_hybrid': [],\n",
    "            'recommendations_hybrid_mmr_static': [],\n",
    "            'recommendations_hybrid_mab_mmr': [],\n",
    "            'mab_arm_index': None\n",
    "        }\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "try:\n",
    "    # 1. Coba muat dari cache terlebih dahulu\n",
    "    evaluation_df = pd.read_pickle(EVAL_CACHE_FILE)\n",
    "    logger.info(f\"‚úÖ Berhasil memuat 'evaluation_df' dari cache: {EVAL_CACHE_FILE}\")\n",
    "    print(f\"‚úÖ Berhasil memuat 'evaluation_df' dari cache: {EVAL_CACHE_FILE}\")\n",
    "    print(f\"   Total users di cache: {len(evaluation_df)}\")\n",
    "    \n",
    "    # Cek apakah cache valid (memiliki kolom baru)\n",
    "    if 'mab_arm_index' not in evaluation_df.columns:\n",
    "         print(\"‚ö†Ô∏è Cache tidak valid (kolom 'mab_arm_index' hilang). Menjalankan ulang evaluasi.\")\n",
    "         raise FileNotFoundError # Paksa eksekusi ulang\n",
    "\n",
    "except FileNotFoundError:\n",
    "    logger.warning(f\"Cache '{EVAL_CACHE_FILE}' tidak ditemukan. Memulai evaluasi penuh...\")\n",
    "    print(f\"Cache '{EVAL_CACHE_FILE}' tidak ditemukan. Memulai evaluasi penuh...\")\n",
    "    \n",
    "    # Ambil daftar pengguna yang valid dari CELL 6\n",
    "    eval_users_list = eligible_users\n",
    "    \n",
    "    # Periksa apakah prasyarat ada\n",
    "    if not eval_users_list:\n",
    "        print(\"‚ùå Tidak ada 'eligible_users' untuk dievaluasi. Hentikan.\")\n",
    "        evaluation_df = pd.DataFrame() # Buat df kosong\n",
    "    elif 'hybrid_model_engine' not in globals() or hybrid_model_engine is None:\n",
    "        print(\"‚ùå 'hybrid_model_engine' tidak ditemukan. Jalankan CELL 9 dulu.\")\n",
    "        evaluation_df = pd.DataFrame() # Buat df kosong\n",
    "    else:\n",
    "        # Tentukan ukuran batch (seberapa banyak user dievaluasi bersamaan)\n",
    "        batch_size = 20\n",
    "        num_batches = (len(eval_users_list) + batch_size - 1) // batch_size\n",
    "        all_results = []\n",
    "        \n",
    "        print(f\"Memulai evaluasi untuk {len(eval_users_list)} pengguna dalam {num_batches} batch...\")\n",
    "        \n",
    "        for i in tqdm(range(num_batches), desc=\"Mengevaluasi batch pengguna\"):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, len(eval_users_list))\n",
    "            user_batch = eval_users_list[start_idx:end_idx]\n",
    "            \n",
    "            # Buat daftar 'tasks' untuk dijalankan secara konkuren\n",
    "            tasks = [\n",
    "                run_evaluation_for_user(user_id, hybrid_model_engine) \n",
    "                for user_id in user_batch\n",
    "            ]\n",
    "            \n",
    "            # Jalankan semua tasks di batch ini secara bersamaan\n",
    "            batch_results = await asyncio.gather(*tasks)\n",
    "            all_results.extend(batch_results)\n",
    "        \n",
    "        # 2. Konversi hasil ke DataFrame\n",
    "        evaluation_df = pd.DataFrame(all_results)\n",
    "        \n",
    "        # 3. Simpan ke cache untuk penggunaan di masa depan\n",
    "        try:\n",
    "            evaluation_df.to_pickle(EVAL_CACHE_FILE)\n",
    "            print(f\"\\n‚úÖ Evaluasi selesai. Hasil disimpan ke cache: {EVAL_CACHE_FILE}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ö†Ô∏è Peringatan: Evaluasi selesai, tapi GAGAL menyimpan ke cache: {e}\")\n",
    "\n",
    "# --- Tampilkan Hasil ---\n",
    "if not evaluation_df.empty:\n",
    "    print(f\"\\nTotal users dievaluasi: {len(evaluation_df)}\")\n",
    "    print(\"Contoh hasil 'evaluation_df':\")\n",
    "    # Tampilkan 5 baris pertama\n",
    "    display(evaluation_df.head())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 'evaluation_df' kosong. Tidak ada hasil untuk ditampilkan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2164ec2-853a-45e7-9b29-1910ed80a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 11: ANALISIS METRIK PERFORMA & UJI SIGNIFIKANSI =====\n",
    "import pickle\n",
    "from scipy import stats # Pastikan diimpor dari CELL 4\n",
    "\n",
    "# Nama file untuk cache hasil performa\n",
    "PERF_CACHE_FILE = 'performance_results_cache.pkl'\n",
    "\n",
    "# Model-model yang akan kita evaluasi\n",
    "MODEL_NAMES = [\n",
    "    'cf', \n",
    "    'cb', \n",
    "    'hybrid', \n",
    "    'hybrid_mmr_static', \n",
    "    'hybrid_mab_mmr'\n",
    "]\n",
    "\n",
    "def calculate_reward(ndcg, diversity, ndcg_weight=0.5, diversity_weight=0.5):\n",
    "    \"\"\"\n",
    "    Menghitung 'reward' untuk MAB berdasarkan kombinasi akurasi dan keragaman.\n",
    "    Skor reward antara 0 dan 1.\n",
    "    \"\"\"\n",
    "    # Pastikan metrik berada dalam rentang [0, 1]\n",
    "    ndcg = max(0, min(1, ndcg))\n",
    "    diversity = max(0, min(1, diversity))\n",
    "    \n",
    "    return (ndcg_weight * ndcg) + (diversity_weight * diversity)\n",
    "\n",
    "async def calculate_all_metrics():\n",
    "    \"\"\"\n",
    "    Fungsi utama untuk menghitung semua metrik dari evaluation_df\n",
    "    dan melatih MAB.\n",
    "    \"\"\"\n",
    "    logger.info(\"Memulai kalkulasi metrik performa...\")\n",
    "    \n",
    "    # 1. Dapatkan prasyarat\n",
    "    if 'cb_model_engine' not in globals() or cb_model_engine is None:\n",
    "        print(\"‚ùå 'cb_model_engine' tidak ditemukan. Jalankan CELL 9.\")\n",
    "        return None, None\n",
    "        \n",
    "    # Dapatkan map kategori (dibutuhkan untuk metrik diversity)\n",
    "    item_categories_map = cb_model_engine.get_categories()\n",
    "    if not item_categories_map:\n",
    "        print(\"‚ùå Peta kategori kosong. Tidak bisa menghitung diversity.\")\n",
    "        return None, None\n",
    "        \n",
    "    if evaluation_df.empty:\n",
    "        print(\"‚ùå 'evaluation_df' kosong. Jalankan CELL 10.\")\n",
    "        return None, None\n",
    "\n",
    "    # 2. Siapkan dictionary untuk menyimpan SEMUA skor individu\n",
    "    # Ini penting untuk t-test!\n",
    "    all_individual_scores = {\n",
    "        model: {'precision': [], 'recall': [], 'ndcg': [], 'diversity': []} \n",
    "        for model in MODEL_NAMES\n",
    "    }\n",
    "\n",
    "    # 3. Iterasi per pengguna di evaluation_df\n",
    "    for _, row in tqdm(evaluation_df.iterrows(), total=len(evaluation_df), desc=\"Menghitung Metrik Pengguna\"):\n",
    "        user_id = row['user_id']\n",
    "        \n",
    "        # Dapatkan ground truth (item > 4.0) untuk pengguna ini\n",
    "        gt = ground_truth_cache.get(user_id, [])\n",
    "        if not gt:\n",
    "            continue # Lewati jika pengguna tidak punya ground truth\n",
    "\n",
    "        # Hitung metrik untuk setiap model\n",
    "        for model_key in MODEL_NAMES:\n",
    "            col_name = f'recommendations_{model_key}'\n",
    "            recs = row[col_name]\n",
    "            \n",
    "            # Hitung semua metrik\n",
    "            p_k = precision_at_k(recs, gt, k=10)\n",
    "            r_k = recall_at_k(recs, gt, k=10)\n",
    "            n_k = ndcg_at_k(recs, gt, k=10)\n",
    "            d_k = intra_list_diversity(recs, item_categories_map)\n",
    "            \n",
    "            # Simpan skor individu\n",
    "            all_individual_scores[model_key]['precision'].append(p_k)\n",
    "            all_individual_scores[model_key]['recall'].append(r_k)\n",
    "            all_individual_scores[model_key]['ndcg'].append(n_k)\n",
    "            all_individual_scores[model_key]['diversity'].append(d_k)\n",
    "            \n",
    "            # 4. KHUSUS UNTUK MAB: Hitung reward dan update model MAB\n",
    "            if model_key == 'hybrid_mab_mmr':\n",
    "                arm_index = row['mab_arm_index']\n",
    "                if arm_index is not None:\n",
    "                    # Hitung reward\n",
    "                    reward = calculate_reward(n_k, d_k)\n",
    "                    # Update MAB (dari CELL 9)\n",
    "                    mab_engine.update(arm_index, reward)\n",
    "\n",
    "    logger.info(\"Kalkulasi metrik individu selesai.\")\n",
    "    \n",
    "    # 5. Hitung rata-rata (summary) dari skor individu\n",
    "    performance_summary = {}\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìä HASIL PERFORMA RATA-RATA MODEL üìä\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for model_name, metrics in all_individual_scores.items():\n",
    "        if not metrics['precision']: # Cek jika ada data\n",
    "            logger.warning(f\"Tidak ada data metrik untuk model: {model_name}\")\n",
    "            continue\n",
    "            \n",
    "        summary = {\n",
    "            'Precision@10': np.mean(metrics['precision']),\n",
    "            'Recall@10': np.mean(metrics['recall']),\n",
    "            'NDCG@10': np.mean(metrics['ndcg']),\n",
    "            'Diversity': np.mean(metrics['diversity']),\n",
    "            'Precision_Std': np.std(metrics['precision']),\n",
    "            'Recall_Std': np.std(metrics['recall']),\n",
    "            'NDCG_Std': np.std(metrics['ndcg']),\n",
    "            'Diversity_Std': np.std(metrics['diversity']),\n",
    "            'Users': len(metrics['precision'])\n",
    "        }\n",
    "        performance_summary[model_name] = summary\n",
    "        \n",
    "        # Cetak hasil\n",
    "        print(f\"\\n--- Model: {model_name.upper()} ---\")\n",
    "        print(f\"  Precision@10: {summary['Precision@10']:.4f} (¬±{summary['Precision_Std']:.4f})\")\n",
    "        print(f\"  Recall@10:    {summary['Recall@10']:.4f} (¬±{summary['Recall_Std']:.4f})\")\n",
    "        print(f\"  NDCG@10:      {summary['NDCG@10']:.4f} (¬±{summary['NDCG_Std']:.4f})\")\n",
    "        print(f\"  Diversity:    {summary['Diversity']:.4f} (¬±{summary['Diversity_Std']:.4f})\")\n",
    "        print(f\"  (n_users = {summary['Users']})\")\n",
    "\n",
    "    return performance_summary, all_individual_scores\n",
    "\n",
    "def run_significance_tests(individual_scores, proposed_model='hybrid_mab_mmr', baselines=None):\n",
    "    \"\"\"\n",
    "    Menjalankan Paired T-Test antara model yang diusulkan dan semua baseline.\n",
    "    \"\"\"\n",
    "    if baselines is None:\n",
    "        baselines = ['cf', 'cb', 'hybrid', 'hybrid_mmr_static']\n",
    "        \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"üî¨ UJI SIGNIFIKANSI STATISTIK (PAIRED T-TEST) üî¨\")\n",
    "    print(f\"   Model Utama: {proposed_model}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    metrics_to_test = ['precision', 'recall', 'ndcg', 'diversity']\n",
    "    \n",
    "    # Data untuk hasil t-test (jika ingin disimpan)\n",
    "    test_results = {}\n",
    "\n",
    "    for baseline in baselines:\n",
    "        if baseline == proposed_model:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n--- Perbandingan: [{proposed_model.upper()}] vs [{baseline.upper()}] ---\")\n",
    "        test_results[baseline] = {}\n",
    "        \n",
    "        for metric in metrics_to_test:\n",
    "            # Ambil list skor individu untuk kedua model\n",
    "            proposed_scores = individual_scores[proposed_model][metric]\n",
    "            baseline_scores = individual_scores[baseline][metric]\n",
    "            \n",
    "            # Pastikan panjangnya sama\n",
    "            min_len = min(len(proposed_scores), len(baseline_scores))\n",
    "            if min_len < 2:\n",
    "                print(f\"  METRIC {metric.upper()}: Tidak cukup data (n={min_len})\")\n",
    "                continue\n",
    "            \n",
    "            proposed_scores = proposed_scores[:min_len]\n",
    "            baseline_scores = baseline_scores[:min_len]\n",
    "            \n",
    "            # Lakukan Paired T-Test\n",
    "            # H0: Rata-rata kedua model SAMA\n",
    "            # H1: Rata-rata kedua model BERBEDA\n",
    "            t_stat, p_value = stats.ttest_rel(proposed_scores, baseline_scores)\n",
    "            \n",
    "            print(f\"\\n  Metric: {metric.upper()}\")\n",
    "            print(f\"    {proposed_model} (Mean): {np.mean(proposed_scores):.4f}\")\n",
    "            print(f\"    {baseline} (Mean): {np.mean(baseline_scores):.4f}\")\n",
    "            print(f\"    P-Value: {p_value:.6f}\")\n",
    "            \n",
    "            # Interpretasi hasil\n",
    "            if p_value < 0.05: # Ambang batas signifikansi 5%\n",
    "                if t_stat > 0:\n",
    "                    print(\"    HASIL: ‚úÖ Signifikan! Model Anda LEBIH BAIK.\")\n",
    "                else:\n",
    "                    print(\"    HASIL: ‚ùå Signifikan! Model Anda LEBIH BURUK.\")\n",
    "            else:\n",
    "                print(\"    HASIL: ‚ö†Ô∏è Tidak signifikan. Perbedaan tidak terbukti.\")\n",
    "            \n",
    "            test_results[baseline][metric] = {'t_stat': t_stat, 'p_value': p_value}\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# --- MAIN EXECUTION CELL 11 ---\n",
    "try:\n",
    "    # 1. Coba muat dari cache dulu\n",
    "    with open(PERF_CACHE_FILE, 'rb') as f:\n",
    "        cached_data = pickle.load(f)\n",
    "        performance_summary = cached_data['summary']\n",
    "        all_individual_scores = cached_data['individual']\n",
    "    print(f\"‚úÖ Berhasil memuat HASIL PERFORMA dari cache: {PERF_CACHE_FILE}\")\n",
    "    \n",
    "    # Tampilkan summary dari cache\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìä HASIL PERFORMA RATA-RATA (DARI CACHE) üìä\")\n",
    "    print(\"=\"*50)\n",
    "    for model_name, summary in performance_summary.items():\n",
    "        print(f\"\\n--- Model: {model_name.upper()} ---\")\n",
    "        print(f\"  Precision@10: {summary['Precision@10']:.4f} (¬±{summary['Precision_Std']:.4f})\")\n",
    "        print(f\"  Recall@10:    {summary['Recall@10']:.4f} (¬±{summary['Recall_Std']:.4f})\")\n",
    "        print(f\"  NDCG@10:      {summary['NDCG@10']:.4f} (¬±{summary['NDCG_Std']:.4f})\")\n",
    "        print(f\"  Diversity:    {summary['Diversity']:.4f} (¬±{summary['Diversity_Std']:.4f})\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    logger.warning(f\"Cache '{PERF_CACHE_FILE}' tidak ditemukan. Menjalankan kalkulasi penuh...\")\n",
    "    print(f\"Cache '{PERF_CACHE_FILE}' tidak ditemukan. Menjalankan kalkulasi penuh...\")\n",
    "    \n",
    "    # 2. Jalankan kalkulasi penuh\n",
    "    performance_summary, all_individual_scores = await calculate_all_metrics()\n",
    "    \n",
    "    # 3. Simpan hasil ke cache\n",
    "    if performance_summary:\n",
    "        try:\n",
    "            with open(PERF_CACHE_FILE, 'wb') as f:\n",
    "                pickle.dump({'summary': performance_summary, 'individual': all_individual_scores}, f)\n",
    "            print(f\"\\n‚úÖ Hasil performa disimpan ke cache: {PERF_CACHE_FILE}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ö†Ô∏è Gagal menyimpan hasil performa ke cache: {e}\")\n",
    "\n",
    "# 4. JALANKAN UJI SIGNIFIKANSI STATISTIK\n",
    "# Ini akan selalu berjalan (tidak perlu di-cache) karena cepat\n",
    "if 'all_individual_scores' in globals() and all_individual_scores:\n",
    "    statistical_test_results = run_significance_tests(all_individual_scores)\n",
    "    \n",
    "    # 5. Tampilkan status MAB setelah di-update\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ü§ñ STATUS MAB SETELAH UPDATE ü§ñ\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Lambda (Arm) | Jumlah Dipilih (Pulls) | Rata-rata Reward\")\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    mab_counts = mab_engine.counts\n",
    "    mab_rewards = mab_engine.avg_rewards\n",
    "    mab_arms = mab_engine.arms\n",
    "    \n",
    "    for i in range(len(mab_arms)):\n",
    "        print(f\"  Œª = {mab_arms[i]:.1f}     | {mab_counts[i]:<20} | {mab_rewards[i]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nTotal pulls: {mab_engine.total_pulls}\")\n",
    "    best_arm_index = np.argmax(mab_rewards)\n",
    "    print(f\"üèÜ Lambda terbaik (berdasarkan reward): {mab_arms[best_arm_index]:.1f} (Reward: {mab_rewards[best_arm_index]:.4f})\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Tidak ada 'all_individual_scores'. Tidak bisa menjalankan Uji Signifikansi atau menampilkan MAB.\")\n",
    "\n",
    "# Buat DataFrame dari summary untuk visualisasi\n",
    "performance_df = pd.DataFrame(performance_summary).T.reset_index().rename(columns={'index': 'Model'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a4bc2-2571-4332-876b-5081545f5559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 11.5: ANALISIS KONVERGENSI MAB =====\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulasi konvergensi MAB (dari data evaluation_df)\n",
    "user_rewards = []\n",
    "cumulative_best_lambda = []\n",
    "\n",
    "print(\"üìà Analisis Konvergensi MAB:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Simulasi learning curve\n",
    "for i, (_, row) in enumerate(evaluation_df.iterrows()):\n",
    "    if row['mab_arm_index'] is not None:\n",
    "        arm_idx = row['mab_arm_index']\n",
    "        # Hitung reward yang seharusnya\n",
    "        # (ambil dari metrik yang sudah dihitung di all_individual_scores)\n",
    "        user_id = row['user_id']\n",
    "        # Ini simulasi sederhana - bisa diperbaiki\n",
    "        user_rewards.append(mab_engine.avg_rewards[arm_idx])\n",
    "        cumulative_best_lambda.append(mab_engine.arms[np.argmax(mab_engine.avg_rewards[:arm_idx+1])])\n",
    "\n",
    "# Plot learning curve\n",
    "if user_rewards:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    \n",
    "    # Plot 1: Cumulative Average Reward\n",
    "    cumulative_avg = np.cumsum(user_rewards) / np.arange(1, len(user_rewards) + 1)\n",
    "    ax1.plot(cumulative_avg, linewidth=2)\n",
    "    ax1.set_xlabel('Jumlah Iterasi (User)', fontsize=12)\n",
    "    ax1.set_ylabel('Rata-rata Reward Kumulatif', fontsize=12)\n",
    "    ax1.set_title('Konvergensi Reward MAB', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Best Lambda Evolution\n",
    "    ax2.plot(cumulative_best_lambda, linewidth=2, color='orange')\n",
    "    ax2.set_xlabel('Jumlah Iterasi (User)', fontsize=12)\n",
    "    ax2.set_ylabel('Lambda Terbaik (Cumulative)', fontsize=12)\n",
    "    ax2.set_title('Evolusi Pemilihan Lambda Optimal', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylim([-0.1, 1.1])\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('mab_convergence_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Grafik konvergensi disimpan: mab_convergence_analysis.png\")\n",
    "    print(f\"   Final average reward: {cumulative_avg[-1]:.4f}\")\n",
    "    print(f\"   Converged lambda: {cumulative_best_lambda[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a729dd75-3b02-449f-b21d-1dfad68cc994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 12: VISUALISASI HASIL PERFORMA (VERSI BERSIH TANPA WARNING) =====\n",
    "\n",
    "# Periksa apakah data yang dibutuhkan ada\n",
    "if 'performance_df' not in globals() or performance_df.empty:\n",
    "    print(\"‚ùå 'performance_df' tidak ditemukan. Jalankan CELL 11 terlebih dahulu.\")\n",
    "elif 'all_individual_scores' not in globals() or not all_individual_scores:\n",
    "    print(\"‚ùå 'all_individual_scores' tidak ditemukan. Jalankan CELL 11 terlebih dahulu.\")\n",
    "else:\n",
    "    print(\"‚úÖ Memulai pembuatan visualisasi (versi bersih)...\")\n",
    "    \n",
    "    # --- 1. GRAFIK BATANG PERBANDINGAN RATA-RATA ---\n",
    "    \n",
    "    model_order = ['cf', 'cb', 'hybrid', 'hybrid_mmr_static', 'hybrid_mab_mmr']\n",
    "    palette = {\n",
    "        'cf': 'gray', \n",
    "        'cb': 'lightblue', \n",
    "        'hybrid': 'blue', \n",
    "        'hybrid_mmr_static': 'orange', \n",
    "        'hybrid_mab_mmr': 'green' # Highlight\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    fig.suptitle('Perbandingan Rata-rata Metrik Model', fontsize=20, fontweight='bold')\n",
    "    \n",
    "    metrics_to_plot = [\n",
    "        ('Precision@10', 'Precision@10'), \n",
    "        ('Recall@10', 'Recall@10'), \n",
    "        ('NDCG@10', 'NDCG@10'), \n",
    "        ('Diversity', 'Diversity')\n",
    "    ]\n",
    "    \n",
    "    for ax, (metric_col, title) in zip(axes.flatten(), metrics_to_plot):\n",
    "        sns.barplot(\n",
    "            data=performance_df, \n",
    "            x='Model', \n",
    "            y=metric_col, \n",
    "            ax=ax, \n",
    "            order=model_order,\n",
    "            palette=palette,\n",
    "            hue='Model',\n",
    "            legend=False\n",
    "        )\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(f'{p.get_height():.4f}', (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                        ha='center', va='center', xytext=(0, 9), textcoords='offset points')\n",
    "        \n",
    "        ax.set_title(title, fontsize=16)\n",
    "        ax.set_xlabel('Model', fontsize=12)\n",
    "        ax.set_ylabel('Score', fontsize=12)\n",
    "        # --- PERBAIKAN: Cara modern untuk memutar label ---\n",
    "        ax.tick_params(axis='x', rotation=15)\n",
    "        # ------------------------------------------------\n",
    "        ax.set_ylim(top=ax.get_ylim()[1] * 1.15)\n",
    "        \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig('performance_comparison_bar.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # --- 2. BOX PLOT DISTRIBUSI SKOR ---\n",
    "    plot_data = []\n",
    "    for model_name, metrics in all_individual_scores.items():\n",
    "        for metric_name, scores in metrics.items():\n",
    "            for score in scores:\n",
    "                plot_data.append({'Model': model_name, 'Metric': metric_name, 'Score': score})\n",
    "    individual_df = pd.DataFrame(plot_data)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    fig.suptitle('Distribusi Skor Metrik Model', fontsize=20, fontweight='bold')\n",
    "\n",
    "    for ax, metric_name in zip(axes.flatten(), ['precision', 'recall', 'ndcg', 'diversity']):\n",
    "        sns.boxplot(\n",
    "            data=individual_df[individual_df['Metric'] == metric_name],\n",
    "            x='Model',\n",
    "            y='Score',\n",
    "            ax=ax,\n",
    "            order=model_order,\n",
    "            palette=palette,\n",
    "            hue='Model',\n",
    "            legend=False\n",
    "        )\n",
    "        ax.set_title(f'Distribusi {metric_name.upper()}', fontsize=16)\n",
    "        ax.set_xlabel('Model', fontsize=12)\n",
    "        ax.set_ylabel('Score', fontsize=12)\n",
    "        # --- PERBAIKAN: Cara modern untuk memutar label ---\n",
    "        ax.tick_params(axis='x', rotation=15)\n",
    "        # ------------------------------------------------\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig('performance_distribution_boxplot.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # --- 3. PARETO FRONTIER (TRADE-OFF AKURASI vs DIVERSITY) ---\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    pareto_data = performance_df.set_index('Model').loc[model_order]\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        data=pareto_data, x='Diversity', y='NDCG@10', hue='Model', \n",
    "        palette=palette, s=200, style='Model', markers=True, edgecolor='black'\n",
    "    )\n",
    "    \n",
    "    for model_name in pareto_data.index:\n",
    "        plt.text(x=pareto_data.loc[model_name, 'Diversity'] + 0.005,\n",
    "                 y=pareto_data.loc[model_name, 'NDCG@10'], s=model_name,\n",
    "                 fontdict=dict(color='black', size=10))\n",
    "    \n",
    "    pareto_sorted = pareto_data.sort_values(by='Diversity')\n",
    "    pareto_points = []\n",
    "    current_max_ndcg = -float('inf')\n",
    "    \n",
    "    for model_name, row in pareto_sorted.iterrows():\n",
    "        if row['NDCG@10'] > current_max_ndcg:\n",
    "            pareto_points.append((row['Diversity'], row['NDCG@10']))\n",
    "            current_max_ndcg = row['NDCG@10']\n",
    "    \n",
    "    if len(pareto_points) > 1:\n",
    "        pareto_x, pareto_y = zip(*pareto_points)\n",
    "        plt.plot(pareto_x, pareto_y, 'k--', alpha=0.5, label='Pareto Frontier (Optimal Trade-off)')\n",
    "    \n",
    "    plt.title('Trade-off: Akurasi (NDCG) vs. Keragaman (Diversity)', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Keragaman (Intra-List Diversity)', fontsize=14)\n",
    "    plt.ylabel('Akurasi Peringkat (NDCG@10)', fontsize=14)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.savefig('pareto_frontier_tradeoff.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # --- 4. DISTRIBUSI PEMILIHAN LAMBDA (ARM) MAB ---\n",
    "    if 'mab_engine' in globals():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        mab_counts = mab_engine.counts\n",
    "        mab_arms_float = mab_engine.arms \n",
    "        \n",
    "        # --- PERBAIKAN: Mengganti 'color' dengan 'palette' ---\n",
    "        sns.barplot(\n",
    "            x=mab_arms_float, \n",
    "            y=mab_counts, \n",
    "            palette='dark:blue',  # <--- Ini perbaikannya\n",
    "            hue=mab_arms_float, \n",
    "            dodge=False, \n",
    "            legend=False\n",
    "        )\n",
    "        # -------------------------------------------------\n",
    "        \n",
    "        plt.xticks(ticks=range(len(mab_arms_float)), labels=[f\"{arm:.1f}\" for arm in mab_arms_float])\n",
    "        \n",
    "        plt.title('Distribusi Pemilihan Lengan (Lambda) oleh MAB', fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('Nilai Lambda (Œª) untuk MMR', fontsize=14)\n",
    "        plt.ylabel('Jumlah Pemilihan (Pulls)', fontsize=14)\n",
    "        plt.savefig('mab_lambda_distribution.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è 'mab_engine' tidak ditemukan. Tidak bisa mem-plot distribusi lambda.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6ac560-66fb-43e9-86d8-0d5c1eda2a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 13: ANALISIS DISTRIBUSI, COVERAGE, DAN LONG TAIL =====\n",
    "\n",
    "# --- 1. Fungsi Helper ---\n",
    "\n",
    "def calculate_gini_coefficient(all_recommendations):\n",
    "    \"\"\"\n",
    "    Menghitung Gini Coefficient untuk mengukur ketidaksetaraan \n",
    "    distribusi rekomendasi.\n",
    "    0 = kesetaraan sempurna, 1 = ketidaksetaraan total.\n",
    "    \"\"\"\n",
    "    if not all_recommendations:\n",
    "        return 0.0\n",
    "        \n",
    "    # Hitung frekuensi setiap item\n",
    "    item_counts = Counter(all_recommendations)\n",
    "    counts = np.array(list(item_counts.values()))\n",
    "    \n",
    "    # Rumus Gini Coefficient\n",
    "    n = len(counts)\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    counts_sorted = np.sort(counts)\n",
    "    index = np.arange(1, n + 1)\n",
    "    \n",
    "    # Gini index\n",
    "    gini = (np.sum((2 * index - n - 1) * counts_sorted)) / (n * np.sum(counts_sorted))\n",
    "    return float(gini)\n",
    "\n",
    "def calculate_catalog_coverage(all_recommendations, all_items):\n",
    "    \"\"\"\n",
    "    Menghitung Catalog Coverage.\n",
    "    (Item unik yang direkomendasikan) / (Total item unik di katalog)\n",
    "    \"\"\"\n",
    "    if not all_items:\n",
    "        return 0.0\n",
    "    \n",
    "    recommended_items_unique = set(all_recommendations)\n",
    "    return len(recommended_items_unique) / len(all_items)\n",
    "\n",
    "def plot_long_tail_distribution(model_recommendations_map, item_popularity):\n",
    "    \"\"\"\n",
    "    Membuat plot Long Tail untuk membandingkan semua model.\n",
    "    model_recommendations_map: dict {'model_name': [all_recs]}\n",
    "    item_popularity: pd.Series (index=destination_id, values=rating_count)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # 1. Plot Popularitas Item (Garis Abu-abu)\n",
    "    # Urutkan item dari paling populer ke paling tidak populer\n",
    "    popularity_sorted = item_popularity.sort_values(ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    ax1 = plt.gca() # Dapatkan axis saat ini\n",
    "    ax1.plot(popularity_sorted.index, popularity_sorted.values, \n",
    "             color='gray', linestyle='--', label='Popularitas Item (Long Tail)', alpha=0.7)\n",
    "    ax1.set_yscale('log') # Skala log untuk popularitas\n",
    "    ax1.set_xlabel('Item (Diurutkan berdasarkan Popularitas)', fontsize=12)\n",
    "    ax1.set_ylabel('Popularitas (Jumlah Rating) - Skala Log', fontsize=12, color='gray')\n",
    "    ax1.tick_params(axis='y', labelcolor='gray')\n",
    "\n",
    "    # 2. Plot Frekuensi Rekomendasi (untuk setiap model)\n",
    "    ax2 = ax1.twinx() # Buat axis Y kedua\n",
    "    \n",
    "    # Dapatkan palet warna dari CELL 12\n",
    "    palette = {\n",
    "        'cf': 'gray', 'cb': 'lightblue', 'hybrid': 'blue', \n",
    "        'hybrid_mmr_static': 'orange', 'hybrid_mab_mmr': 'green'\n",
    "    }\n",
    "    \n",
    "    for model_name, all_recs in model_recommendations_map.items():\n",
    "        if not all_recs:\n",
    "            continue\n",
    "            \n",
    "        # Hitung frekuensi rekomendasi\n",
    "        rec_counts = Counter(all_recs)\n",
    "        rec_counts_df = pd.DataFrame.from_dict(rec_counts, orient='index', columns=['rec_count'])\n",
    "        \n",
    "        # Gabungkan dengan popularitas dan urutkan\n",
    "        plot_data = rec_counts_df.join(item_popularity).fillna(0)\n",
    "        plot_data = plot_data.sort_values(by='popularity', ascending=False)\n",
    "        \n",
    "        # Plot frekuensi rekomendasi\n",
    "        ax2.plot(\n",
    "            plot_data.index.values, \n",
    "            plot_data['rec_count'].values, \n",
    "            label=f'Rekomendasi {model_name}', \n",
    "            color=palette.get(model_name, 'red'), \n",
    "            alpha=0.8\n",
    "        )\n",
    "        \n",
    "    ax2.set_ylabel('Frekuensi Rekomendasi (Jumlah Direkomendasikan)', fontsize=12, color='black')\n",
    "    ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "    plt.title('Analisis Long Tail: Popularitas Item vs Frekuensi Rekomendasi', fontsize=16, fontweight='bold')\n",
    "    # Gabungkan legend dari kedua axis\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc='upper right')\n",
    "    \n",
    "    plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "    plt.savefig('long_tail_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# --- MAIN EXECUTION CELL 13 ---\n",
    "\n",
    "if 'evaluation_df' not in globals() or evaluation_df.empty:\n",
    "    print(\"‚ùå 'evaluation_df' tidak ditemukan. Jalankan CELL 10 terlebih dahulu.\")\n",
    "else:\n",
    "    # 1. Kumpulkan semua rekomendasi dari 'evaluation_df'\n",
    "    all_recommendations_map = {}\n",
    "    for model_key in MODEL_NAMES:\n",
    "        col_name = f'recommendations_{model_key}'\n",
    "        # Gabungkan semua list rekomendasi menjadi satu list besar\n",
    "        all_recs_list = [item for sublist in evaluation_df[col_name].dropna() for item in sublist]\n",
    "        all_recommendations_map[model_key] = all_recs_list\n",
    "\n",
    "    # 2. Dapatkan item katalog\n",
    "    # Gunakan 'ratings_df' (dari CELL 6) untuk katalog lengkap\n",
    "    all_destination_ids = set(ratings_df['destination_id'].unique())\n",
    "    \n",
    "    # 3. Hitung Gini dan Coverage\n",
    "    distribution_stats = {}\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìä ANALISIS DISTRIBUSI DAN COVERAGE üìä\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for model_name, all_recs in all_recommendations_map.items():\n",
    "        if not all_recs:\n",
    "            print(f\"--- Model: {model_name.upper()} ---\")\n",
    "            print(\"  (Tidak ada rekomendasi)\")\n",
    "            continue\n",
    "            \n",
    "        gini = calculate_gini_coefficient(all_recs)\n",
    "        coverage = calculate_catalog_coverage(all_recs, all_destination_ids)\n",
    "        \n",
    "        distribution_stats[model_name] = {\n",
    "            'Gini Coefficient (Lower is Better)': gini,\n",
    "            'Catalog Coverage (Higher is Better)': coverage,\n",
    "            'Total Recommendations': len(all_recs),\n",
    "            'Unique Items Recommended': len(set(all_recs))\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n--- Model: {model_name.upper()} ---\")\n",
    "        print(f\"  Gini Coefficient:  {gini:.4f}\")\n",
    "        print(f\"  Catalog Coverage:  {coverage:.4f} ({distribution_stats[model_name]['Unique Items Recommended']} / {len(all_destination_ids)} items)\")\n",
    "        \n",
    "    # Tampilkan sebagai DataFrame\n",
    "    distribution_df = pd.DataFrame(distribution_stats).T\n",
    "    display(distribution_df)\n",
    "\n",
    "    # 4. Buat Plot Long Tail\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìà MEMBUAT PLOT LONG TAIL üìà\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Hitung popularitas item (jumlah rating di data training)\n",
    "    item_popularity = train_df['destination_id'].value_counts().rename('popularity')\n",
    "    \n",
    "    # Plot\n",
    "    plot_long_tail_distribution(all_recommendations_map, item_popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d901fcc1-2942-4ef6-8207-8a5e1503e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 14: EXPORT HASIL AKHIR =====\n",
    "import json\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üì¶ MENYIMPAN HASIL AKHIR KE FILE üì¶\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "EXPORT_DIR = \"evaluation_results\"\n",
    "import os\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "print(f\"Hasil akan disimpan di folder: {EXPORT_DIR}/\")\n",
    "\n",
    "# --- 1. Simpan Ringkasan Metrik Performa (performance_df) ---\n",
    "if 'performance_df' in globals() and not performance_df.empty:\n",
    "    try:\n",
    "        csv_path = os.path.join(EXPORT_DIR, \"results_summary_metrics.csv\")\n",
    "        excel_path = os.path.join(EXPORT_DIR, \"results_summary_metrics.xlsx\")\n",
    "        \n",
    "        performance_df.to_csv(csv_path, index=False)\n",
    "        performance_df.to_excel(excel_path, index=False)\n",
    "        \n",
    "        print(f\"‚úÖ 1. Ringkasan Metrik Rata-rata disimpan ke:\")\n",
    "        print(f\"   - {csv_path}\")\n",
    "        print(f\"   - {excel_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Gagal menyimpan 'performance_df': {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 1. 'performance_df' tidak ditemukan. File tidak disimpan.\")\n",
    "\n",
    "# --- 2. Simpan Metrik Distribusi (distribution_df) ---\n",
    "if 'distribution_df' in globals() and not distribution_df.empty:\n",
    "    try:\n",
    "        csv_path = os.path.join(EXPORT_DIR, \"results_distribution_metrics.csv\")\n",
    "        excel_path = os.path.join(EXPORT_DIR, \"results_distribution_metrics.xlsx\")\n",
    "        \n",
    "        distribution_df.to_csv(csv_path) # Simpan index (nama model)\n",
    "        distribution_df.to_excel(excel_path) # Simpan index\n",
    "        \n",
    "        print(f\"\\n‚úÖ 2. Metrik Distribusi (Gini, Coverage) disimpan ke:\")\n",
    "        print(f\"   - {csv_path}\")\n",
    "        print(f\"   - {excel_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Gagal menyimpan 'distribution_df': {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 2. 'distribution_df' tidak ditemukan. File tidak disimpan.\")\n",
    "    \n",
    "# --- 3. Simpan Hasil Uji Signifikansi (statistical_test_results) ---\n",
    "if 'statistical_test_results' in globals() and statistical_test_results:\n",
    "    try:\n",
    "        json_path = os.path.join(EXPORT_DIR, \"results_statistical_tests.json\")\n",
    "        \n",
    "        # Gunakan json.dump untuk menyimpan file .json\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(statistical_test_results, f, indent=4)\n",
    "            \n",
    "        print(f\"\\n‚úÖ 3. Hasil Uji Signifikansi (T-Test) disimpan ke:\")\n",
    "        print(f\"   - {json_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Gagal menyimpan 'statistical_test_results': {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 3. 'statistical_test_results' tidak ditemukan. File tidak disimpan.\")\n",
    "\n",
    "# --- 4. Simpan Semua Skor Individu (individual_df) ---\n",
    "# (Kita buat 'individual_df' di CELL 12 untuk plotting)\n",
    "if 'individual_df' in globals() and not individual_df.empty:\n",
    "    try:\n",
    "        # Gunakan kompresi 'gzip' karena file ini bisa sangat besar\n",
    "        csv_path = os.path.join(EXPORT_DIR, \"results_individual_scores.csv.gz\")\n",
    "        \n",
    "        individual_df.to_csv(csv_path, index=False, compression='gzip')\n",
    "        \n",
    "        print(f\"\\n‚úÖ 4. Semua Skor Individu (mentah) disimpan ke:\")\n",
    "        print(f\"   - {csv_path} (terkompresi)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Gagal menyimpan 'individual_df': {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 4. 'individual_df' tidak ditemukan. File tidak disimpan.\")\n",
    "\n",
    "# --- 5. Tampilkan file cache utama (untuk referensi) ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìÅ LOKASI FILE CACHE UTAMA (DATA MENTAH) üìÅ\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Rekomendasi mentah per pengguna: ./{EVAL_CACHE_FILE}\")\n",
    "print(f\"Hasil performa mentah (cache):   ./{PERF_CACHE_FILE}\")\n",
    "\n",
    "print(\"\\n\\nüéâ === EVALUASI SELESAI === üéâ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652704df-be77-4204-b10d-0bd8f4504456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 15.5: SENSITIVITY ANALYSIS - REWARD FUNCTION =====\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üî¨ SENSITIVITY ANALYSIS: REWARD FUNCTION WEIGHTING üî¨\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚ÑπÔ∏è Analisis ini menggunakan data yang SUDAH dievaluasi.\")\n",
    "print(\"   Kita akan RE-CALCULATE reward dengan bobot berbeda untuk melihat\")\n",
    "print(\"   lambda mana yang akan dipilih MAB jika reward function berbeda.\\n\")\n",
    "\n",
    "# Konfigurasi bobot yang akan diuji\n",
    "sensitivity_configs = [\n",
    "    {'name': '70-30 (NDCG Priority)', 'ndcg_w': 0.7, 'div_w': 0.3},\n",
    "    {'name': '60-40 (Moderate NDCG)', 'ndcg_w': 0.6, 'div_w': 0.4},\n",
    "    {'name': '50-50 (Balanced)', 'ndcg_w': 0.5, 'div_w': 0.5},\n",
    "    {'name': '40-60 (Moderate Div)', 'ndcg_w': 0.4, 'div_w': 0.6},\n",
    "    {'name': '30-70 (Diversity Priority)', 'ndcg_w': 0.3, 'div_w': 0.7},\n",
    "]\n",
    "\n",
    "sensitivity_results = []\n",
    "all_mab_eval_data = pd.DataFrame() # DataFrame kosong sebagai default\n",
    "\n",
    "try:\n",
    "    # 1. Persiapkan DataFrame data mentah (bergantung pada CELL 10 & 11)\n",
    "    # Ini harus ada di luar loop agar 'NameError' tidak terjadi\n",
    "    ndcg_scores = all_individual_scores['hybrid_mab_mmr']['ndcg']\n",
    "    diversity_scores = all_individual_scores['hybrid_mab_mmr']['diversity']\n",
    "    # Ambil arm_indices dari evaluation_df\n",
    "    arm_indices = evaluation_df[evaluation_df['mab_arm_index'].notnull()]['mab_arm_index'].astype(int)\n",
    "    \n",
    "    min_len = min(len(ndcg_scores), len(diversity_scores), len(arm_indices))\n",
    "    \n",
    "    all_mab_eval_data = pd.DataFrame({\n",
    "        'ndcg': ndcg_scores[:min_len],\n",
    "        'diversity': diversity_scores[:min_len],\n",
    "        'mab_arm_index': arm_indices[:min_len]\n",
    "    })\n",
    "    \n",
    "    if all_mab_eval_data.empty:\n",
    "        raise ValueError(\"Data evaluasi MAB kosong.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR: Gagal mempersiapkan data untuk simulasi. Jalankan CELL 10 & 11 dulu.\")\n",
    "    print(f\"   Detail Error: {e}\")\n",
    "\n",
    "# --- Jalankan simulasi HANYA jika data berhasil disiapkan ---\n",
    "if not all_mab_eval_data.empty:\n",
    "    \n",
    "    for config in sensitivity_configs:\n",
    "        print(f\"\\n--- Testing: {config['name']} ---\")\n",
    "        \n",
    "        # Buat MAB baru yang bersih untuk setiap simulasi\n",
    "        test_mab = SimpleMAB(n_arms=11)\n",
    "\n",
    "        # Re-calculate reward dari data existing\n",
    "        for _, row in tqdm(all_mab_eval_data.iterrows(), total=len(all_mab_eval_data), desc=f\"Simulating {config['name']}\"):\n",
    "            \n",
    "            # 1. Ambil data asli\n",
    "            ndcg_val = row['ndcg']\n",
    "            diversity_val = row['diversity']\n",
    "            arm_index_raw = row['mab_arm_index']\n",
    "\n",
    "            if pd.isna(arm_index_raw):\n",
    "                continue\n",
    "                \n",
    "            # --- PERBAIKAN: Konversi ke integer ---\n",
    "            try:\n",
    "                arm_index = int(arm_index_raw)\n",
    "            except ValueError:\n",
    "                print(f\"Skipping invalid arm_index: {arm_index_raw}\")\n",
    "                continue\n",
    "            # ------------------------------------\n",
    "            \n",
    "            # 2. Cek jika arm_index valid\n",
    "            if arm_index is None or arm_index < 0 or arm_index >= test_mab.n_arms:\n",
    "                continue\n",
    "            \n",
    "            # 3. Hitung reward BARU (PERBAIKAN URUTAN)\n",
    "            reward_new = calculate_reward(ndcg_val, diversity_val, config['ndcg_w'], config['div_w'])\n",
    "\n",
    "            # 4. Lakukan increment count secara manual (PERBAIKAN LOGIKA 0.0)\n",
    "            # Simulasi ini harus meniru 'select_arm' (yg menambah count) SEBELUM 'update'\n",
    "            test_mab.total_pulls += 1\n",
    "            if 0 <= arm_index < test_mab.n_arms:\n",
    "                test_mab.counts[arm_index] += 1\n",
    "                # 5. Panggil update\n",
    "                test_mab.update(arm_index, reward_new)\n",
    "            else:\n",
    "                # Batalkan penambahan pull jika arm tidak valid\n",
    "                test_mab.total_pulls -= 1\n",
    "                print(f\"Skipping out-of-bounds arm_index: {arm_index}\")\n",
    "\n",
    "            # 5. Panggil update (sekarang reward_new sudah ada)\n",
    "            test_mab.update(arm_index, reward_new)\n",
    "\n",
    "        # Analisis hasil simulasi\n",
    "        \n",
    "        # PERBAIKAN: Gunakan .avg_rewards, bukan .rewards\n",
    "        best_arm_idx = np.argmax(test_mab.avg_rewards)\n",
    "        best_lambda = test_mab.arms[best_arm_idx]\n",
    "        best_reward = test_mab.avg_rewards[best_arm_idx]\n",
    "        \n",
    "        # PERBAIKAN: Gunakan .avg_rewards, bukan .rewards\n",
    "        avg_reward = np.mean(test_mab.avg_rewards)\n",
    "        std_reward = np.std(test_mab.avg_rewards)\n",
    "        \n",
    "        result = {\n",
    "            'Config': config['name'],\n",
    "            'NDCG_Weight': config['ndcg_w'],\n",
    "            'Diversity_Weight': config['div_w'],\n",
    "            'Best_Lambda': best_lambda,\n",
    "            'Best_Reward': best_reward,\n",
    "            'Avg_Reward': avg_reward,\n",
    "            'Std_Reward': std_reward\n",
    "        }\n",
    "        sensitivity_results.append(result)\n",
    "\n",
    "        print(f\"  Best Lambda: {best_lambda:.1f}\")\n",
    "        print(f\"  Best Reward: {best_reward:.4f}\")\n",
    "        print(f\"  Avg Reward: {avg_reward:.4f} (¬±{std_reward:.4f})\")\n",
    "\n",
    "    # --- Tampilkan Tabel Summary ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä SUMMARY: SENSITIVITY ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    sensitivity_df = pd.DataFrame(sensitivity_results)\n",
    "    \n",
    "    # Atur presisi desimal untuk tampilan\n",
    "    pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "    \n",
    "    # Tampilkan tabel yang rapi\n",
    "    print(tabulate(sensitivity_df, headers='keys', tablefmt='psql', showindex=True))\n",
    "    \n",
    "    # Reset format display\n",
    "    pd.reset_option('display.float_format')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
