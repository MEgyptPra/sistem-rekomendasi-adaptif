{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d733b-f50a-493e-bbe9-f4b4ea10fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 1: SETUP DAN IMPORT =====\n",
    "!pip install sqlalchemy psycopg2-binary nest_asyncio asyncpg tenacity scikit-learn matplotlib seaborn pandas numpy tabulate\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Path ke kode sistem rekomendasi\n",
    "SISTEM_RECOMMENDER_PATH = '../pariwisata-recommender/'\n",
    "sys.path.append(SISTEM_RECOMMENDER_PATH)\n",
    "\n",
    "# Import dari kode sistem\n",
    "try:\n",
    "    from app.models.rating import Rating\n",
    "    from app.models.destinations import Destination\n",
    "    from app.models.category import Category\n",
    "    from app.models.user import User\n",
    "    from app.services.collaborative_recommender import CollaborativeRecommender\n",
    "    from app.services.content_based_recommender import ContentBasedRecommender\n",
    "    from app.services.hybrid_recommender import HybridRecommender\n",
    "    from app.services.mab_optimizer import MABOptimizer\n",
    "    from app.services.real_time_data import RealTimeContextService\n",
    "    \n",
    "    print(\"âœ… Berhasil mengimpor kode sistem!\")\n",
    "    KODE_SISTEM_TERSEDIA = True\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âš ï¸ Tidak bisa mengimpor kode sistem: {e}\")\n",
    "    KODE_SISTEM_TERSEDIA = False\n",
    "\n",
    "# Import library lainnya\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import select, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de76d3ca-2c70-4bff-90a4-bb843477d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 2: LOAD DATA =====\n",
    "async def load_data_ratings():\n",
    "    \"\"\"Load data ratings dari database\"\"\"\n",
    "    try:\n",
    "        async with get_db() as db:\n",
    "            result = await db.execute(select(Rating))\n",
    "            ratings = result.scalars().all()\n",
    "            \n",
    "            data = []\n",
    "            for rating in ratings:\n",
    "                data.append({\n",
    "                    'user_id': rating.user_id,\n",
    "                    'destination_id': rating.destination_id, \n",
    "                    'rating': float(rating.rating),\n",
    "                    'created_at': rating.created_at\n",
    "                })\n",
    "            \n",
    "            df = pd.DataFrame(data)\n",
    "            print(f\"âœ… Loaded {len(df)} ratings\")\n",
    "            return df\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Gagal load ratings: {e}\")\n",
    "        raise\n",
    "\n",
    "async def load_data_destinations():\n",
    "    \"\"\"Load data destinasi dari database\"\"\"\n",
    "    try:\n",
    "        async with get_db() as db:\n",
    "            from sqlalchemy.orm import selectinload\n",
    "            \n",
    "            result = await db.execute(\n",
    "                select(Destination).options(selectinload(Destination.categories))\n",
    "            )\n",
    "            destinations = result.scalars().all()\n",
    "            \n",
    "            features = {}\n",
    "            for dest in destinations:\n",
    "                categories = [cat.name for cat in dest.categories]\n",
    "                features[dest.id] = {\n",
    "                    'name': dest.name,\n",
    "                    'description': dest.description or '',\n",
    "                    'location': dest.address or '',\n",
    "                    'categories': categories,\n",
    "                    'category': categories[0] if categories else 'Umum'\n",
    "                }\n",
    "            \n",
    "            print(f\"âœ… Loaded {len(features)} destinations dengan categories\")\n",
    "            return features\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Gagal load destinations: {e}\")\n",
    "        raise\n",
    "\n",
    "# Load data\n",
    "ratings_df = await load_data_ratings()\n",
    "destination_features = await load_data_destinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f373acfa-89e7-4f20-825b-fa6fff21426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 2.5: PREPROCESSING DATA UNTUK COLLABORATIVE FILTERING =====\n",
    "print(\"ðŸ”§ PREPROCESSING DATA UNTUK COLLABORATIVE FILTERING...\")\n",
    "\n",
    "# 1. Identifikasi dan handle duplikat\n",
    "print(\"1. Memeriksa duplikat data...\")\n",
    "duplicate_mask = ratings_df.duplicated(subset=['user_id', 'destination_id'], keep=False)\n",
    "duplicate_count = duplicate_mask.sum()\n",
    "\n",
    "print(f\"   Ditemukan {duplicate_count} entri duplikat\")\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    print(\"   Contoh data duplikat:\")\n",
    "    duplicates = ratings_df[duplicate_mask].sort_values(['user_id', 'destination_id'])\n",
    "    print(duplicates.head(10))\n",
    "    \n",
    "    # Group by dan ambil rata-rata rating untuk duplikat\n",
    "    print(\"   Menggabungkan duplikat dengan rata-rata rating...\")\n",
    "    ratings_df_clean = ratings_df.groupby(['user_id', 'destination_id'])['rating'].mean().reset_index()\n",
    "else:\n",
    "    ratings_df_clean = ratings_df.copy()\n",
    "\n",
    "print(f\"   Data setelah cleaning: {len(ratings_df_clean)} ratings\")\n",
    "\n",
    "# 2. Filter user yang memiliki minimal 2 rating untuk evaluasi yang valid\n",
    "print(\"2. Memfilter user dengan minimal 2 rating...\")\n",
    "user_rating_counts = ratings_df_clean['user_id'].value_counts()\n",
    "users_with_min_ratings = user_rating_counts[user_rating_counts >= 2].index\n",
    "ratings_df_filtered = ratings_df_clean[ratings_df_clean['user_id'].isin(users_with_min_ratings)]\n",
    "\n",
    "print(f\"   User dengan minimal 2 rating: {len(users_with_min_ratings)}\")\n",
    "print(f\"   Ratings setelah filter user: {len(ratings_df_filtered)}\")\n",
    "\n",
    "# 3. Pastikan tidak ada duplikat lagi\n",
    "final_duplicates = ratings_df_filtered.duplicated(subset=['user_id', 'destination_id']).sum()\n",
    "print(f\"3. Duplikat setelah processing: {final_duplicates}\")\n",
    "\n",
    "if final_duplicates > 0:\n",
    "    print(\"   âš ï¸ Masih ada duplikat, melakukan cleanup final...\")\n",
    "    ratings_df_filtered = ratings_df_filtered.drop_duplicates(subset=['user_id', 'destination_id'])\n",
    "\n",
    "# 4. Simpan data yang sudah dibersihkan untuk digunakan model\n",
    "ratings_df_processed = ratings_df_filtered.copy()\n",
    "\n",
    "print(\"âœ… PREPROCESSING SELESAI!\")\n",
    "print(f\"ðŸ“Š Data final: {len(ratings_df_processed)} ratings\")\n",
    "print(f\"ðŸ“Š Unique users: {ratings_df_processed['user_id'].nunique()}\")\n",
    "print(f\"ðŸ“Š Unique destinations: {ratings_df_processed['destination_id'].nunique()}\")\n",
    "\n",
    "# Buat DataFrame untuk training collaborative\n",
    "collab_training_df = ratings_df_processed[['user_id', 'destination_id', 'rating']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02586f6-2aba-4178-be25-548024a79674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 3: INISIALISASI MODEL =====\n",
    "print(\"ðŸš€ Inisialisasi model...\")\n",
    "\n",
    "# Gunakan data yang SUDAH DIPROSES dari cell 2.5\n",
    "ratings_df_for_split = ratings_df_processed.copy()\n",
    "\n",
    "print(f\"ðŸ“Š Data untuk training: {len(ratings_df_for_split)} ratings\")\n",
    "print(f\"ðŸ“Š Unique users: {ratings_df_for_split['user_id'].nunique()}\")\n",
    "print(f\"ðŸ“Š Unique destinations: {ratings_df_for_split['destination_id'].nunique()}\")\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = train_test_split(\n",
    "    ratings_df_for_split, \n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š Training set: {len(train_df)} ratings\")\n",
    "print(f\"ðŸ“Š Test set: {len(test_df)} ratings\")\n",
    "\n",
    "# Inisialisasi model\n",
    "cf_model = CollaborativeRecommender()\n",
    "cb_model = ContentBasedRecommender()\n",
    "hybrid_model = HybridRecommender()\n",
    "mab_optimizer = MABOptimizer(\n",
    "    n_arms=11,\n",
    "    exploration_param=2.0,\n",
    "    persistence_file=\"data/mab_state.json\"\n",
    ")\n",
    "context_service = RealTimeContextService()\n",
    "\n",
    "print(\"âœ… Model berhasil diinisialisasi!\")\n",
    "\n",
    "# Train model\n",
    "print(\"ðŸ‹ï¸ Melatih model...\")\n",
    "\n",
    "try:\n",
    "    async with get_db() as db:\n",
    "        # Train Collaborative Filtering \n",
    "        print(\"  - Training Collaborative Filtering dengan NMF...\")\n",
    "        try:\n",
    "            result_cf = await cf_model.train(db)\n",
    "            print(f\"  âœ… Collaborative: {result_cf['users_count']} users, {result_cf['items_count']} items\")\n",
    "            print(f\"     Matrix: {result_cf['matrix_shape']}, NMF components: {result_cf['nmf_components']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ Collaborative failed: {e}\")\n",
    "        \n",
    "        # Train Content-Based\n",
    "        print(\"  - Training Content-Based...\")\n",
    "        try:\n",
    "            result_cb = await cb_model.train(db)\n",
    "            print(\"  âœ… Content-Based trained\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ Content-Based failed: {e}\")\n",
    "        \n",
    "        # Train Hybrid  \n",
    "        print(\"  - Training Hybrid...\")\n",
    "        try:\n",
    "            result_hybrid = await hybrid_model.train(db)\n",
    "            print(\"  âœ… Hybrid trained\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ Hybrid failed: {e}\")\n",
    "\n",
    "    print(\"ðŸŽ¯ Training completed!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Training error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b806471-e8f1-4e24-8aa0-5ab5d3b9e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL DEBUG: CEK DATA DI DATABASE =====\n",
    "async def check_database_duplicates():\n",
    "    \"\"\"Cek duplikat langsung di database\"\"\"\n",
    "    async with get_db() as db:\n",
    "        # Query untuk cek duplikat\n",
    "        result = await db.execute(\"\"\"\n",
    "            SELECT user_id, destination_id, COUNT(*) as count \n",
    "            FROM ratings \n",
    "            GROUP BY user_id, destination_id \n",
    "            HAVING COUNT(*) > 1\n",
    "            LIMIT 10\n",
    "        \"\"\")\n",
    "        duplicates = result.fetchall()\n",
    "        \n",
    "        print(\"ðŸ” DUPLIKAT DI DATABASE:\")\n",
    "        for dup in duplicates:\n",
    "            user_id, dest_id, count = dup\n",
    "            print(f\"   User {user_id}, Destination {dest_id}: {count} entries\")\n",
    "            \n",
    "        return len(duplicates)\n",
    "\n",
    "duplicate_count = await check_database_duplicates()\n",
    "print(f\"Total duplikat di database: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b07e7-170f-4953-829c-514b988ad1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 4: EVALUATION FRAMEWORK =====\n",
    "class ComprehensiveEvaluator:\n",
    "    def __init__(self, train_df, test_df, item_features):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.item_features = item_features\n",
    "        self.total_items = len(item_features)\n",
    "        \n",
    "        # Calculate item popularity from training data\n",
    "        self.item_popularity = train_df['destination_id'].value_counts().to_dict()\n",
    "        self.total_ratings = len(train_df)\n",
    "        \n",
    "        # Available categories for diversity calculation\n",
    "        self.available_categories = set()\n",
    "        for features in item_features.values():\n",
    "            if 'category' in features:\n",
    "                self.available_categories.add(features['category'])\n",
    "    \n",
    "    def precision_at_k(self, recs_ids, ground_truth_ids, k=10):\n",
    "        if not recs_ids or k == 0:\n",
    "            return 0.0\n",
    "        recs_ids = recs_ids[:k]\n",
    "        return len(set(recs_ids) & set(ground_truth_ids)) / min(k, len(recs_ids))\n",
    "    \n",
    "    def recall_at_k(self, recs_ids, ground_truth_ids, k=10):\n",
    "        if not recs_ids or not ground_truth_ids:\n",
    "            return 0.0\n",
    "        recs_ids = recs_ids[:k]\n",
    "        return len(set(recs_ids) & set(ground_truth_ids)) / len(ground_truth_ids)\n",
    "    \n",
    "    def ndcg_at_k(self, recs_ids, ground_truth_ids, k=10):\n",
    "        if not recs_ids or not ground_truth_ids:\n",
    "            return 0.0\n",
    "            \n",
    "        recs_ids = recs_ids[:k]\n",
    "        \n",
    "        # Calculate DCG\n",
    "        dcg = 0.0\n",
    "        for i, did in enumerate(recs_ids):\n",
    "            if did in ground_truth_ids:\n",
    "                dcg += 1 / np.log2(i + 2)\n",
    "                \n",
    "        # Calculate IDCG\n",
    "        ideal_hits = min(len(ground_truth_ids), k)\n",
    "        idcg = sum(1 / np.log2(i + 2) for i in range(ideal_hits))\n",
    "        \n",
    "        return dcg / idcg if idcg > 0 else 0.0\n",
    "    \n",
    "    def intra_list_diversity(self, recs_ids, k=10):\n",
    "        if len(recs_ids) < 2:\n",
    "            return 0.0\n",
    "            \n",
    "        recs_ids = recs_ids[:k]\n",
    "        \n",
    "        # Count categories\n",
    "        category_counts = {}\n",
    "        for item_id in recs_ids:\n",
    "            if item_id in self.item_features:\n",
    "                category = self.item_features[item_id].get('category', 'Unknown')\n",
    "                category_counts[category] = category_counts.get(category, 0) + 1\n",
    "        \n",
    "        # Calculate diversity as inverse of category concentration\n",
    "        total = sum(category_counts.values())\n",
    "        if total == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        category_proportions = [count / total for count in category_counts.values()]\n",
    "        \n",
    "        # Gini-based diversity (1 - Gini coefficient)\n",
    "        if len(category_proportions) > 1:\n",
    "            category_proportions.sort()\n",
    "            n = len(category_proportions)\n",
    "            index = np.arange(1, n + 1)\n",
    "            gini = (np.sum((2 * index - n - 1) * np.array(category_proportions))) / (n * np.sum(category_proportions))\n",
    "            return 1 - gini\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    def coverage_at_k(self, all_recommendations, k=10):\n",
    "        all_recommended_items = set()\n",
    "        \n",
    "        for recs in all_recommendations:\n",
    "            all_recommended_items.update(recs[:k])\n",
    "            \n",
    "        return len(all_recommended_items) / self.total_items\n",
    "    \n",
    "    def novelty(self, recs_ids, k=10):\n",
    "        if not recs_ids:\n",
    "            return 0.0\n",
    "            \n",
    "        recs_ids = recs_ids[:k]\n",
    "        novelty_score = 0.0\n",
    "        valid_items = 0\n",
    "        \n",
    "        for item_id in recs_ids:\n",
    "            popularity = self.item_popularity.get(item_id, 0)\n",
    "            popularity_norm = popularity / self.total_ratings if self.total_ratings > 0 else 0\n",
    "            if popularity_norm > 0:\n",
    "                novelty_score += -math.log2(popularity_norm)\n",
    "                valid_items += 1\n",
    "        \n",
    "        return novelty_score / valid_items if valid_items > 0 else 0.0\n",
    "    \n",
    "    def gini_coefficient(self, all_recommendations):\n",
    "        item_rec_counts = {}\n",
    "        \n",
    "        for recs in all_recommendations:\n",
    "            for item_id in recs:\n",
    "                item_rec_counts[item_id] = item_rec_counts.get(item_id, 0) + 1\n",
    "        \n",
    "        if not item_rec_counts:\n",
    "            return 0.0\n",
    "            \n",
    "        counts = np.array(sorted(item_rec_counts.values()))\n",
    "        n = len(counts)\n",
    "        index = np.arange(1, n + 1)\n",
    "        gini = (np.sum((2 * index - n - 1) * counts)) / (n * np.sum(counts))\n",
    "        return gini\n",
    "    \n",
    "    def calculate_diversity_reward(self, recs_ids, ground_truth_ids, k=10):\n",
    "        metrics_weights = {\n",
    "            'precision': 0.1,\n",
    "            'diversity': 0.7,\n",
    "            'novelty': 0.2\n",
    "        }\n",
    "    \n",
    "        precision = self.precision_at_k(recs_ids, ground_truth_ids, k)\n",
    "        diversity = self.intra_list_diversity(recs_ids, k)\n",
    "        novelty = self.novelty(recs_ids, k)\n",
    "\n",
    "        # Composite reward dengan emphasis on diversity\n",
    "        reward = (metrics_weights['precision'] * precision + \n",
    "                  metrics_weights['diversity'] * diversity + \n",
    "                  metrics_weights['novelty'] * novelty)\n",
    "    \n",
    "        return max(reward, 0.01)\n",
    "\n",
    "print(\"âœ… Evaluation framework defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b01c0c-5bea-40dd-8ee9-7cca9630bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 5: DATA LOADING & PREPROCESSING =====\n",
    "async def load_ratings_data():\n",
    "    \"\"\"Load data dari database atau gunakan synthetic data\"\"\"\n",
    "    try:\n",
    "        # Coba load dari database\n",
    "        async with get_db() as db:\n",
    "            from app.models.rating import Rating\n",
    "            result = await db.execute(select(Rating))\n",
    "            rows = result.scalars().all()\n",
    "        \n",
    "        data = [{'user_id': r.user_id, 'destination_id': r.destination_id, 'rating': float(r.rating)} for r in rows]\n",
    "        ratings_df = pd.DataFrame(data)\n",
    "        print(f\"âœ… Loaded {len(ratings_df)} ratings from database\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Cannot load from database: {e}. Using synthetic data...\")\n",
    "        \n",
    "        # Generate synthetic data\n",
    "        n_users = 100\n",
    "        n_destinations = 50\n",
    "        n_ratings = 1000\n",
    "        \n",
    "        user_ids = list(range(1, n_users + 1))\n",
    "        destination_ids = list(range(1, n_destinations + 1))\n",
    "        \n",
    "        synthetic_ratings = []\n",
    "        random.seed(42)\n",
    "        \n",
    "        for _ in range(n_ratings):\n",
    "            user_id = random.choice(user_ids)\n",
    "            destination_id = random.choice(destination_ids)\n",
    "            rating = random.randint(1, 5)\n",
    "            synthetic_ratings.append({\n",
    "                'user_id': user_id,\n",
    "                'destination_id': destination_id,\n",
    "                'rating': rating\n",
    "            })\n",
    "        \n",
    "        ratings_df = pd.DataFrame(synthetic_ratings)\n",
    "        print(f\"âœ… Created synthetic dataset with {len(ratings_df)} ratings\")\n",
    "    \n",
    "    return ratings_df\n",
    "\n",
    "async def get_item_features():\n",
    "    \"\"\"Get item features dari database atau buat synthetic\"\"\"\n",
    "    try:\n",
    "        async with get_db() as db:\n",
    "            query = text(\"\"\"\n",
    "            SELECT d.id as destination_id, \n",
    "                   COALESCE(c.name, 'Unknown') as category_name,\n",
    "                   d.name as destination_name\n",
    "            FROM destinations d\n",
    "            LEFT JOIN destination_categories dc ON d.id = dc.destination_id\n",
    "            LEFT JOIN categories c ON c.id = dc.category_id\n",
    "            \"\"\")\n",
    "            result = await db.execute(query)\n",
    "            rows = result.fetchall()\n",
    "            \n",
    "            item_features = {}\n",
    "            for row in rows:\n",
    "                destination_id = row[0]\n",
    "                category = row[1]\n",
    "                name = row[2]\n",
    "                \n",
    "                item_features[destination_id] = {\n",
    "                    'category': category,\n",
    "                    'name': name\n",
    "                }\n",
    "            \n",
    "            print(f\"âœ… Loaded features for {len(item_features)} destinations from database\")\n",
    "            return item_features\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Cannot load item features: {e}. Using synthetic features...\")\n",
    "        \n",
    "        # Get destinations from ratings\n",
    "        ratings_df = await load_ratings_data()\n",
    "        destinations = ratings_df['destination_id'].unique()\n",
    "        \n",
    "        categories = ['Wisata Alam', 'Wisata Budaya & Sejarah', 'Wisata Kuliner', \n",
    "                     'Wisata Buatan/Rekreasi', 'Wisata Keluarga', 'Wisata Kesehatan & Wellness',\n",
    "                     'Wisata Petualangan', 'Wisata Religi', 'Wisata Olahraga']\n",
    "        \n",
    "        item_features = {}\n",
    "        for i, destination_id in enumerate(destinations):\n",
    "            category = categories[i % len(categories)]\n",
    "            name = f'Destination_{destination_id}'\n",
    "            item_features[destination_id] = {\n",
    "                'category': category,\n",
    "                'name': name\n",
    "            }\n",
    "        \n",
    "        print(f\"âœ… Created synthetic features for {len(item_features)} destinations\")\n",
    "        return item_features\n",
    "\n",
    "# Load data\n",
    "ratings_df = await safe_db_operation(load_ratings_data)\n",
    "item_features = await safe_db_operation(get_item_features)\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = train_test_split(\n",
    "    ratings_df, \n",
    "    test_size=EVALUATION_CONFIG['test_size'], \n",
    "    random_state=EVALUATION_CONFIG['random_state'],\n",
    "    stratify=ratings_df['user_id'].apply(lambda x: min(x % 10, 5))\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š Data Summary:\")\n",
    "print(f\"   Total ratings: {len(ratings_df)}\")\n",
    "print(f\"   Train set: {len(train_df)}\")\n",
    "print(f\"   Test set: {len(test_df)}\")\n",
    "print(f\"   Unique users: {ratings_df['user_id'].nunique()}\")\n",
    "print(f\"   Unique destinations: {ratings_df['destination_id'].nunique()}\")\n",
    "\n",
    "# Prepare ground truth\n",
    "test_truth = test_df.groupby('user_id')['destination_id'].apply(list).to_dict()\n",
    "eligible_users = [uid for uid in test_truth.keys() if len(test_truth[uid]) >= 2]\n",
    "eligible_users = eligible_users[:EVALUATION_CONFIG['max_evaluation_users']]\n",
    "\n",
    "ground_truth_cache = {}\n",
    "for user_id in eligible_users:\n",
    "    ground_truth_cache[user_id] = test_truth.get(user_id, [])\n",
    "\n",
    "print(f\"ðŸŽ¯ Evaluation setup:\")\n",
    "print(f\"   Eligible users: {len(eligible_users)}\")\n",
    "print(f\"   Ground truth items: {sum(len(v) for v in ground_truth_cache.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb542fc9-a8e1-4c9e-a125-360393093684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 6: MODEL TRAINING =====\n",
    "print(\"ðŸš€ Training models...\")\n",
    "\n",
    "# Train Collaborative Filtering\n",
    "cf_model = CollaborativeRecommender()\n",
    "cf_train_info = await cf_model.train_from_df(train_df)\n",
    "print(f\"âœ… Collaborative Filtering trained: {cf_train_info}\")\n",
    "\n",
    "# Train Content-Based\n",
    "cb_model = ContentBasedRecommender()\n",
    "await cb_model.train(train_df, item_features)\n",
    "\n",
    "# Initialize other components\n",
    "context_component = ContextAwareComponent()\n",
    "evaluator = ComprehensiveEvaluator(train_df, test_df, item_features)\n",
    "\n",
    "# Initialize hybrid model\n",
    "hybrid_model = HybridRecommender(\n",
    "    cf_model=cf_model,\n",
    "    cb_model=cb_model,\n",
    "    context_component=context_component,\n",
    "    evaluator=evaluator,\n",
    "    cf_weight=MODEL_WEIGHTS['cf_weight'],\n",
    "    cb_weight=MODEL_WEIGHTS['cb_weight'],\n",
    "    context_weight=MODEL_WEIGHTS['context_weight']\n",
    ")\n",
    "\n",
    "# Initialize rerankers\n",
    "mmr_static = MMRReranker(lambda_param=0.5, item_popularity=evaluator.item_popularity)\n",
    "mmr_adaptive = MMRReranker(lambda_param=0.3, diversity_strength=2.0, item_popularity=evaluator.item_popularity)\n",
    "mab_optimizer = EnhancedMAB(n_arms=5)\n",
    "\n",
    "print(\"âœ… All models trained and ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d3d960-beef-486c-9577-d9f0e3638832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 7: STREAMLINED EVALUATION =====\n",
    "async def run_comprehensive_evaluation():\n",
    "    \"\"\"Jalankan evaluasi komprehensif dengan caching\"\"\"\n",
    "    print(\"ðŸ”¥ Starting comprehensive evaluation...\")\n",
    "    \n",
    "    # Cache CF recommendations untuk mempercepat\n",
    "    print(\"ðŸ“¦ Caching CF recommendations...\")\n",
    "    cf_cache = {}\n",
    "    \n",
    "    for user_id in tqdm(eligible_users, desc=\"Caching CF\"):\n",
    "        try:\n",
    "            recs = await cf_model.predict(user_id, EVALUATION_CONFIG['num_recommendations'] * 2)\n",
    "            cf_cache[user_id] = recs\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: CF failed for user {user_id}: {e}\")\n",
    "            cf_cache[user_id] = []\n",
    "    \n",
    "    # Evaluasi semua model\n",
    "    print(\"âš¡ Evaluating all models...\")\n",
    "    all_results = []\n",
    "    \n",
    "    for user_id in tqdm(eligible_users, desc=\"Evaluating Users\"):\n",
    "        try:\n",
    "            context = random.choice(CONTEXTS)\n",
    "            \n",
    "            # Get recommendations from all models\n",
    "            cf_recs = cf_cache.get(user_id, [])\n",
    "            cb_recs = await cb_model.predict(user_id, EVALUATION_CONFIG['num_recommendations'] * 2)\n",
    "            hybrid_recs = await hybrid_model.predict(\n",
    "                user_id, \n",
    "                EVALUATION_CONFIG['num_recommendations'] * 2, \n",
    "                context, \n",
    "                cf_recs,\n",
    "                item_features\n",
    "            )\n",
    "            \n",
    "            # Apply reranking\n",
    "            hybrid_mmr_static = await mmr_static.rerank(hybrid_recs, user_id, item_features)\n",
    "            \n",
    "            # MAB-adaptive reranking\n",
    "            selected_arm = mab_optimizer.select_arm(context)\n",
    "            lambda_param = mab_optimizer.get_lambda_for_mmr(selected_arm)\n",
    "            mmr_adaptive.lambda_param = lambda_param\n",
    "            hybrid_mab_mmr = await mmr_adaptive.rerank(hybrid_recs, user_id, item_features)\n",
    "            \n",
    "            # Update MAB\n",
    "            ground_truth = ground_truth_cache.get(user_id, [])\n",
    "            reward = evaluator.calculate_diversity_reward(\n",
    "                [r['destination_id'] for r in hybrid_mab_mmr], \n",
    "                ground_truth\n",
    "            )\n",
    "            mab_optimizer.update(selected_arm, reward, context)\n",
    "            \n",
    "            # Store results\n",
    "            all_results.append({\n",
    "                'user_id': user_id,\n",
    "                'recommendations_cf': [r['destination_id'] for r in cf_recs],\n",
    "                'recommendations_cb': [r['destination_id'] for r in cb_recs],\n",
    "                'recommendations_hybrid': [r['destination_id'] for r in hybrid_recs],\n",
    "                'recommendations_hybrid_mmr_static': [r['destination_id'] for r in hybrid_mmr_static],\n",
    "                'recommendations_hybrid_mab_mmr': [r['destination_id'] for r in hybrid_mab_mmr]\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating user {user_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    evaluation_df = pd.DataFrame(all_results)\n",
    "    print(f\"âœ… Evaluation completed! Processed {len(evaluation_df)} users\")\n",
    "    \n",
    "    return evaluation_df, mab_optimizer\n",
    "\n",
    "# Jalankan evaluasi\n",
    "evaluation_df, mab_optimizer = await run_comprehensive_evaluation()\n",
    "\n",
    "# Simpan hasil\n",
    "if not evaluation_df.empty:\n",
    "    evaluation_df.to_pickle('evaluation_results_optimized.pkl')\n",
    "    print(\"ðŸ’¾ Results saved to 'evaluation_results_optimized.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c0c9e-fe01-4b4f-93ba-3209d9b871c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 8: RESULTS ANALYSIS =====\n",
    "def calculate_comprehensive_metrics(evaluation_df, ground_truth_cache, evaluator):\n",
    "    \"\"\"Hitung semua metrics untuk analisis\"\"\"\n",
    "    model_columns = [col for col in evaluation_df.columns if col.startswith('recommendations_')]\n",
    "    metrics_results = {}\n",
    "    \n",
    "    for model_col in model_columns:\n",
    "        model_name = model_col.replace('recommendations_', '')\n",
    "        print(f\"ðŸ“Š Calculating metrics for {model_name}...\")\n",
    "        \n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        ndcg_scores = []\n",
    "        diversity_scores = []\n",
    "        novelty_scores = []\n",
    "        all_recommendations = []\n",
    "        \n",
    "        for _, row in evaluation_df.iterrows():\n",
    "            user_id = row['user_id']\n",
    "            recs = row[model_col]\n",
    "            ground_truth = ground_truth_cache.get(user_id, [])\n",
    "            \n",
    "            precision_scores.append(evaluator.precision_at_k(recs, ground_truth, 10))\n",
    "            recall_scores.append(evaluator.recall_at_k(recs, ground_truth, 10))\n",
    "            ndcg_scores.append(evaluator.ndcg_at_k(recs, ground_truth, 10))\n",
    "            diversity_scores.append(evaluator.intra_list_diversity(recs, 10))\n",
    "            novelty_scores.append(evaluator.novelty(recs, 10))\n",
    "            all_recommendations.append(recs)\n",
    "        \n",
    "        coverage = evaluator.coverage_at_k(all_recommendations, 10)\n",
    "        gini = evaluator.gini_coefficient(all_recommendations)\n",
    "        \n",
    "        metrics_results[model_name] = {\n",
    "            'precision@10': np.mean(precision_scores),\n",
    "            'recall@10': np.mean(recall_scores),\n",
    "            'ndcg@10': np.mean(ndcg_scores),\n",
    "            'diversity': np.mean(diversity_scores),\n",
    "            'novelty': np.mean(novelty_scores),\n",
    "            'coverage@10': coverage,\n",
    "            'gini': gini,\n",
    "            'precision_scores': precision_scores,\n",
    "            'diversity_scores': diversity_scores,\n",
    "            'ndcg_scores': ndcg_scores\n",
    "        }\n",
    "    \n",
    "    return metrics_results\n",
    "\n",
    "# Calculate metrics\n",
    "metrics_results = calculate_comprehensive_metrics(evaluation_df, ground_truth_cache, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b005e-0479-4a39-ab31-ab76200b491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 9: VISUALIZATION & STATISTICS =====\n",
    "def plot_final_results(metrics_results):\n",
    "    \"\"\"Plot hasil akhir yang komprehensif\"\"\"\n",
    "    models = list(metrics_results.keys())\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Metrics to plot\n",
    "    metrics_config = [\n",
    "        ('precision@10', 'Precision@10', axes[0,0]),\n",
    "        ('recall@10', 'Recall@10', axes[0,1]), \n",
    "        ('ndcg@10', 'NDCG@10', axes[0,2]),\n",
    "        ('diversity', 'Diversity', axes[1,0]),\n",
    "        ('novelty', 'Novelty', axes[1,1]),\n",
    "        ('coverage@10', 'Coverage@10', axes[1,2])\n",
    "    ]\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    for i, (metric, title, ax) in enumerate(metrics_config):\n",
    "        values = [metrics_results[model][metric] for model in models]\n",
    "        bars = ax.bar(models, values, color=colors[:len(models)], alpha=0.7)\n",
    "        ax.set_title(title, fontweight='bold')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, value in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                   f'{value:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary table\n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "    print(\"FINAL EVALUATION RESULTS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    summary_data = []\n",
    "    for model in models:\n",
    "        row = [model]\n",
    "        for metric in ['precision@10', 'recall@10', 'ndcg@10', 'diversity', 'novelty', 'coverage@10', 'gini']:\n",
    "            row.append(f\"{metrics_results[model][metric]:.4f}\")\n",
    "        summary_data.append(row)\n",
    "    \n",
    "    headers = ['Model', 'Precision@10', 'Recall@10', 'NDCG@10', 'Diversity', 'Novelty', 'Coverage@10', 'Gini']\n",
    "    print(tabulate(summary_data, headers=headers, tablefmt='grid'))\n",
    "    \n",
    "    # Statistical significance\n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    print(\"STATISTICAL SIGNIFICANCE (MAB-MMR vs Others)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    target_model = 'hybrid_mab_mmr'\n",
    "    for metric in ['precision_scores', 'ndcg_scores', 'diversity_scores']:\n",
    "        print(f\"\\\\nðŸ“ˆ {metric.replace('_scores', '').upper()}:\")\n",
    "        target_scores = metrics_results[target_model][metric]\n",
    "        \n",
    "        for baseline in ['cf', 'cb', 'hybrid', 'hybrid_mmr_static']:\n",
    "            if baseline != target_model:\n",
    "                baseline_scores = metrics_results[baseline][metric]\n",
    "                t_stat, p_value = stats.ttest_rel(target_scores, baseline_scores)\n",
    "                improvement = ((np.mean(target_scores) - np.mean(baseline_scores)) / np.mean(baseline_scores)) * 100\n",
    "                star = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"\"\n",
    "                print(f\"   {target_model} vs {baseline:20}: p={p_value:.6f} {star} | Improvement: {improvement:+.2f}%\")\n",
    "\n",
    "# Plot results\n",
    "plot_final_results(metrics_results)\n",
    "\n",
    "print(\"ðŸŽ‰ EVALUATION COMPLETED SUCCESSFULLY!\")\n",
    "print(\"ðŸ“ Results saved and visualized!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
