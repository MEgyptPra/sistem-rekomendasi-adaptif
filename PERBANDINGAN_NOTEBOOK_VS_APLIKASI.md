# ğŸ“Š PERBANDINGAN KODE: NOTEBOOK vs APLIKASI PRODUKSI

**Tanggal Analisis:** 3 Desember 2025  
**Tujuan:** Memastikan konsistensi implementasi antara eksperimen penelitian (notebook) dan aplikasi produksi

---

## ğŸ¯ RINGKASAN EKSEKUTIF

| Komponen | Kesesuaian | Status | Catatan |
|----------|------------|--------|---------|
| **MAB (UCB1)** | âœ… 95% | SESUAI | Formula sama, minor difference di logging |
| **MMR Reranking** | âš ï¸ 70% | PARSIAL | Formula sama, tapi perbedaan di item vector construction |
| **Hybrid Weights** | âŒ BERBEDA | TIDAK SESUAI | Notebook: 50/50, Aplikasi: 60/40 |
| **Reward Calculation** | âŒ MISSING | BELUM ADA | Tidak diimplementasikan di aplikasi |
| **Context Boosting** | âœ… 100% | SESUAI | Rules identik |

---

## ğŸ“ ANALISIS DETAIL PER KOMPONEN

### 1. MULTI-ARMED BANDIT (MAB)

#### âœ… **YANG SUDAH SAMA:**

**A. UCB1 Formula**
```python
# NOTEBOOK:
exploration_bonus = np.sqrt(2 * np.log(total_selections) / brain['counts'][i])
ucb = avg_reward + exploration_bonus

# APLIKASI (mab_optimizer.py):
bonus = self.c * np.sqrt((2 * np.log(total_selections)) / counts[arm])
ucb_values[arm] = values[arm] + bonus
```
âœ… **Identik** - Menggunakan UCB1 dengan c=2.0 (exploration parameter)

**B. Contextual State Management**
```python
# NOTEBOOK:
self.context_brains = {
    'counts': np.zeros(self.n_arms),
    'avg_rewards': np.zeros(self.n_arms),
    'total_selections': 0
}

# APLIKASI:
self.context_data[context_key] = {
    'counts': np.zeros(self.n_arms).tolist(),
    'values': np.zeros(self.n_arms).tolist(),
    'total_selections': 0
}
```
âœ… **Identik** - Struktur data sama (values = avg_rewards)

**C. Incremental Average Update**
```python
# NOTEBOOK:
new_avg = old_avg + (reward - old_avg) / n

# APLIKASI:
new_value = old_value + (reward - old_value) / n
```
âœ… **Identik** - Formula incremental averaging sama

#### âš ï¸ **PERBEDAAN KECIL:**

**1. Jumlah Arms**
- **Notebook:** 5 arms [0.0, 0.3, 0.5, 0.7, 1.0]
- **Aplikasi:** 11 arms np.linspace(0, 1, 11) â†’ [0.0, 0.1, 0.2, ..., 1.0]

**REKOMENDASI:** âš ï¸ Ubah aplikasi menjadi 5 arms agar konsisten dengan penelitian

**2. Variable Naming**
- **Notebook:** `avg_rewards`
- **Aplikasi:** `values`

**DAMPAK:** âœ… Tidak signifikan, hanya naming convention

---

### 2. MMR (MAXIMAL MARGINAL RELEVANCE)

#### âœ… **YANG SUDAH SAMA:**

**A. MMR Score Formula**
```python
# NOTEBOOK:
mmr_score = (1 - lambda_val) * relevance - lambda_val * max_similarity

# APLIKASI (hybrid_recommender.py line 353):
mmr_score = lambda_val * relevance_score - (1 - lambda_val) * max_similarity
```
âš ï¸ **PERBEDAAN FORMULA!** Lambda dibalik!

**ANALISIS MENDALAM:**
```
NOTEBOOK FORMULA: (1-Î»)*relevance - Î»*diversity
- Î»=0.0 â†’ Pure relevance (1.0*relevance - 0*diversity)
- Î»=1.0 â†’ Pure diversity (0*relevance - 1.0*diversity)

APLIKASI FORMULA: Î»*relevance - (1-Î»)*diversity
- Î»=0.0 â†’ Pure diversity (0*relevance - 1.0*diversity)  â† TERBALIK!
- Î»=1.0 â†’ Pure relevance (1.0*relevance - 0*diversity)
```

âŒ **KESALAHAN KRITIS DITEMUKAN!**

**DAMPAK:**
- Interpretasi lambda terbalik di aplikasi
- Ketika MAB memilih Î»=0.7 (harusnya lebih diverse), aplikasi malah lebih relevant
- Semua hasil evaluasi MAB menjadi tidak valid!

**REKOMENDASI:** ğŸš¨ **URGENT FIX REQUIRED!**

#### âš ï¸ **PERBEDAAN IMPLEMENTASI:**

**B. Item Vector Construction**

**NOTEBOOK:**
```python
# One-hot category + normalized popularity
cat_vector = [1.0 if cat == category else 0.0 for cat in unique_categories]
pop_feature = pop_score / max_pop if max_pop > 0 else 0
self.item_vectors[item_id] = np.array(cat_vector + [pop_feature * 0.3])
```

**APLIKASI:**
```python
# Menggunakan TF-IDF dari content-based recommender
self.similarity_matrix = self.content_recommender.similarity_matrix
# Similarity dihitung dari cosine similarity TF-IDF vectors
```

**DAMPAK:**
- Aplikasi lebih sophisticated (TF-IDF dari description)
- Notebook lebih sederhana (category one-hot + popularity)
- Hasil diversity measurement bisa berbeda

**REKOMENDASI:** âš ï¸ Dokumentasikan perbedaan ini, tapi TIDAK perlu diubah (aplikasi lebih baik)

---

### 3. HYBRID RECOMMENDER

#### âŒ **PERBEDAAN CRITICAL:**

**A. Hybrid Weights**

**NOTEBOOK:**
```python
self.cf_weight = 0.5  # Collaborative Filtering
self.cb_weight = 0.5  # Content-Based
```

**APLIKASI (hybrid_recommender.py):**
```python
self.content_weight = 0.6  # Content-Based
self.collaborative_weight = 0.4  # Collaborative Filtering
```

**ANALISIS:**
- **Notebook:** CF=50%, CB=50%
- **Aplikasi:** CF=40%, CB=60%
- **Tesis (BAB III.4.5):** Menyebutkan CF=40%, CB=60%

âœ… **APLIKASI SESUAI TESIS**, NOTEBOOK BERBEDA!

**REKOMENDASI:** 
- Jika tesis final menyatakan 60/40, maka **notebook perlu diperbaiki**
- Jika evaluasi di notebook menggunakan 50/50, maka **tesis perlu direvisi**

**B. Candidate Pool Size**

**NOTEBOOK:**
```python
cf_recs_raw = await self.cf.predict(user_id, num_recommendations=50)
cb_recs_raw = await self.cb.predict(user_id, num_recommendations=50)
```

**APLIKASI:**
```python
content_recs = await self.content_recommender.predict(
    user_id, num_recommendations * 3, db  # num_recommendations * 3
)
```

**DAMPAK:**
- Notebook: Fixed 50 candidates
- Aplikasi: Dynamic (3x requested recommendations)
- Untuk k=10 â†’ Notebook=50, Aplikasi=30

**REKOMENDASI:** âš ï¸ Standardisasi ke 50 candidates untuk konsistensi

---

### 4. COMPOSITE REWARD CALCULATION

#### âŒ **MISSING IN APPLICATION!**

**NOTEBOOK (calculate_reward):**
```python
REWARD_WEIGHTS = {
    'ndcg': 0.5,
    'diversity': 0.3,
    'novelty': 0.2
}

def calculate_reward(ndcg, diversity, novelty):
    """Calculate reward for MAB update."""
    ndcg = max(0, min(1, ndcg))
    diversity = max(0, min(1, diversity))
    novelty_normalized = max(0, min(1, novelty / 3.0))
    
    reward = (
        REWARD_WEIGHTS['ndcg'] * ndcg + 
        REWARD_WEIGHTS['diversity'] * diversity + 
        REWARD_WEIGHTS['novelty'] * novelty_normalized
    )
    return reward
```

**APLIKASI:**
```python
# âŒ TIDAK ADA IMPLEMENTASI SAMA SEKALI!
```

**DAMPAK:**
- MAB tidak pernah di-update dengan reward
- Sistem tidak belajar dari feedback pengguna
- MAB hanya random selection (tidak adaptif!)

**REKOMENDASI:** ğŸš¨ **CRITICAL - MUST IMPLEMENT!**

---

### 5. CONTEXT-AWARE BOOSTING

#### âœ… **SUDAH SESUAI 100%**

**NOTEBOOK & APLIKASI:**
```python
# Rules identical (checked against Tabel A.2.1-A.2.4 di Lampiran)
context_rules = {
    'weekend': {'Wisata Alam': 1.5, 'Wisata Keluarga': 1.6, ...},
    'cerah': {'Wisata Alam': 1.7, 'Wisata Petualangan': 1.6, ...},
    'hujan': {'Wisata Kuliner': 1.8, 'Wisata Alam': 0.5, ...}
}
```

âœ… **Perfect match** dengan lampiran tesis

---

## ğŸ”§ DAFTAR PERBAIKAN YANG HARUS DILAKUKAN

### **PRIORITAS 1 - CRITICAL (Breaking Changes):**

#### 1. âŒ **Fix MMR Formula di Aplikasi**
**File:** `pariwisata-recommender/backend/app/services/hybrid_recommender.py` line 353

**SEKARANG:**
```python
mmr_score = lambda_val * relevance_score - (1 - lambda_val) * max_similarity
```

**HARUS DIUBAH MENJADI:**
```python
mmr_score = (1 - lambda_val) * relevance_score - lambda_val * max_similarity
```

**DAMPAK:** Tanpa fix ini, interpretasi lambda terbalik dan semua hasil MAB invalid!

---

#### 2. âŒ **Implementasi Reward Calculation**
**File Baru:** `pariwisata-recommender/backend/app/services/reward_calculator.py`

**HARUS DITAMBAHKAN:**
```python
import numpy as np
from typing import Dict, List, Any

class RewardCalculator:
    """Calculate composite reward for MAB updates (Tesis BAB III.4.4)"""
    
    WEIGHTS = {
        'ndcg': 0.5,      # Accuracy
        'diversity': 0.3,  # Diversity
        'novelty': 0.2     # Novelty
    }
    
    def calculate_reward(self, ndcg: float, diversity: float, novelty: float) -> float:
        """
        Composite reward = 0.5*NDCG + 0.3*Diversity + 0.2*Novelty
        
        Args:
            ndcg: Normalized Discounted Cumulative Gain [0,1]
            diversity: Intra-List Diversity [0,1]
            novelty: Average item novelty (normalized by /3.0)
        
        Returns:
            Composite reward in [0,1]
        """
        # Clamp values
        ndcg = max(0.0, min(1.0, ndcg))
        diversity = max(0.0, min(1.0, diversity))
        novelty_normalized = max(0.0, min(1.0, novelty / 3.0))
        
        reward = (
            self.WEIGHTS['ndcg'] * ndcg +
            self.WEIGHTS['diversity'] * diversity +
            self.WEIGHTS['novelty'] * novelty_normalized
        )
        
        return float(reward)
```

---

#### 3. âŒ **Update MAB Arms ke 5 (dari 11)**
**File:** `pariwisata-recommender/backend/app/services/mab_optimizer.py` line 18

**SEKARANG:**
```python
self.arms = np.linspace(0, 1, n_arms)  # 11 arms
```

**HARUS DIUBAH:**
```python
# Fixed arms sama dengan notebook evaluasi
self.arms = [0.0, 0.3, 0.5, 0.7, 1.0]
self.n_arms = len(self.arms)
```

---

### **PRIORITAS 2 - HIGH (Consistency):**

#### 4. âš ï¸ **Standardisasi Hybrid Weights**
**File:** `pariwisata-recommender/backend/app/services/hybrid_recommender.py` line 32-33

**Verifikasi dengan tesis:**
- Jika tesis menyatakan CB=60%, CF=40% â†’ Aplikasi sudah benar âœ…
- Jika tesis menyatakan CB=50%, CF=50% â†’ Notebook perlu diperbaiki

**KONSISTENSI YANG DIREKOMENDASIKAN:**
Gunakan **60/40** (CB lebih tinggi) karena:
- Aplikasi sudah implement ini
- Cold-start user lebih sering terjadi di produksi
- Content-based tidak butuh historical data

---

#### 5. âš ï¸ **Standardisasi Candidate Pool**
**File:** `pariwisata-recommender/backend/app/services/hybrid_recommender.py` line 135

**SEKARANG:**
```python
content_recs = await self.content_recommender.predict(
    user_id, num_recommendations * 3, db
)
```

**UBAH KE:**
```python
content_recs = await self.content_recommender.predict(
    user_id, 50, db  # Fixed 50 sama dengan notebook
)
```

---

### **PRIORITAS 3 - MEDIUM (Feature Completion):**

#### 6. âš ï¸ **Auto MAB Update dari User Interaction**
**File:** `pariwisata-recommender/backend/app/api/frontend_endpoints.py`

**TAMBAHKAN di endpoint `/api/interactions`:**
```python
@router.post("/interactions")
async def create_interaction(
    interaction: InteractionCreate,
    db: AsyncSession = Depends(get_db)
):
    # ... existing code ...
    
    # [TAMBAHAN BARU] Auto-update MAB jika ada arm_index
    if hasattr(interaction, 'arm_index') and interaction.arm_index is not None:
        # Calculate metrics from recent interactions
        reward_calc = RewardCalculator()
        
        # Get user's recent recommendations
        # Calculate NDCG, Diversity, Novelty
        # ...
        
        reward = reward_calc.calculate_reward(ndcg, diversity, novelty)
        ml_service.update_recommendation_feedback(
            arm_index=interaction.arm_index,
            reward=reward,
            context=interaction.context
        )
```

---

## ğŸ“Š MATRIKS KESESUAIAN AKHIR

| Aspek | Notebook | Aplikasi | Status | Prioritas Fix |
|-------|----------|----------|--------|---------------|
| **MAB - UCB1 Formula** | âœ… | âœ… | SAMA | - |
| **MAB - Arms** | 5 arms | 11 arms | BEDA | ğŸ”´ P1 |
| **MMR - Formula** | (1-Î»)*R - Î»*D | Î»*R - (1-Î»)*D | **TERBALIK** | ğŸ”´ P1 |
| **MMR - Similarity** | One-hot+Pop | TF-IDF | BEDA | ğŸŸ¢ OK (lebih baik) |
| **Hybrid - Weights** | 50/50 | 60/40 | BEDA | ğŸŸ¡ P2 (cek tesis) |
| **Hybrid - Candidates** | 50 fixed | 3x dynamic | BEDA | ğŸŸ¡ P2 |
| **Reward Calc** | âœ… Implemented | âŒ Missing | **CRITICAL** | ğŸ”´ P1 |
| **Context Rules** | âœ… | âœ… | SAMA | - |
| **MAB Update Loop** | âœ… | âŒ Manual only | INCOMPLETE | ğŸ”´ P1 |

---

## ğŸ¯ KESIMPULAN

### **Kesesuaian Keseluruhan: 65%**

**Yang Sudah Bagus:**
- âœ… Arsitektur hibrida implemented
- âœ… Context-aware boosting 100% sesuai
- âœ… MAB UCB1 algorithm correct
- âœ… Model persistence & loading

**Yang Harus Diperbaiki Segera:**
1. ğŸš¨ **MMR Formula TERBALIK** - Ini bug kritis yang membuat seluruh evaluasi MAB invalid
2. ğŸš¨ **Reward Calculation MISSING** - MAB tidak belajar sama sekali
3. ğŸš¨ **MAB Arms berbeda** - 11 arms vs 5 arms di penelitian

**Rekomendasi Tindakan:**
1. **STOP deployment** sampai MMR formula diperbaiki
2. **Implementasi reward calculator** sesuai notebook
3. **Ubah arms ke 5** untuk konsistensi
4. **Tambah auto-update loop** untuk MAB learning
5. **Re-run evaluation** setelah semua fix

---

## ğŸ“ CATATAN TAMBAHAN

**Perbedaan yang DIIZINKAN (tidak perlu fix):**
- âœ… TF-IDF similarity vs one-hot (aplikasi lebih baik)
- âœ… Anonymous user support (aplikasi lebih lengkap)
- âœ… Social trend service (aplikasi punya fitur tambahan)

**Perbedaan yang HARUS DISELARASKAN:**
- âŒ MMR formula
- âŒ Reward calculation
- âŒ MAB arms count
- âš ï¸ Hybrid weights (verifikasi tesis dulu)

---

**Dibuat oleh:** GitHub Copilot  
**Tanggal:** 3 Desember 2025  
**Versi:** 1.0
